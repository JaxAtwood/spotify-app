{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spotify_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd6cgX-TTUV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a7ac1b3a-4d91-41d6-ec6e-ad46cd16432f"
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Lambda, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import joblib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW-fT6lVT9Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataframe the data\n",
        "df = pd.read_csv('/content/SpotifyTracks_doubleforloop_genre_year.csv',index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB6e8SeeUdPs",
        "colab_type": "code",
        "outputId": "47f4fdf1-6598-4f86-b03b-0e33ccc95e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "# check data\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist_name</th>\n",
              "      <th>track_name</th>\n",
              "      <th>track_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>year</th>\n",
              "      <th>genre</th>\n",
              "      <th>id</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>key</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gorillaz</td>\n",
              "      <td>On Melancholy Hill</td>\n",
              "      <td>0q6LuUqGLUiCPP1cbdwFs3</td>\n",
              "      <td>75</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.689</td>\n",
              "      <td>233867</td>\n",
              "      <td>0.739</td>\n",
              "      <td>0.509000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0640</td>\n",
              "      <td>-5.810</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>120.423</td>\n",
              "      <td>4</td>\n",
              "      <td>0.578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Avenged Sevenfold</td>\n",
              "      <td>Nightmare</td>\n",
              "      <td>4UEo1b0wWrtHMC8bVqPiH8</td>\n",
              "      <td>70</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.554</td>\n",
              "      <td>374453</td>\n",
              "      <td>0.949</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>-4.928</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0787</td>\n",
              "      <td>129.984</td>\n",
              "      <td>4</td>\n",
              "      <td>0.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Black Keys</td>\n",
              "      <td>Howlin' for You</td>\n",
              "      <td>0grFc6klR3hxoHLcgCYsF4</td>\n",
              "      <td>66</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>2</td>\n",
              "      <td>0.028000</td>\n",
              "      <td>0.705</td>\n",
              "      <td>191800</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.078300</td>\n",
              "      <td>11</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>-6.646</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0931</td>\n",
              "      <td>132.627</td>\n",
              "      <td>4</td>\n",
              "      <td>0.448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My Darkest Days</td>\n",
              "      <td>Porn Star Dancing</td>\n",
              "      <td>3Q8zopc4ABXhysDb1sgLVW</td>\n",
              "      <td>65</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>3</td>\n",
              "      <td>0.013900</td>\n",
              "      <td>0.477</td>\n",
              "      <td>199013</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0756</td>\n",
              "      <td>-3.399</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0837</td>\n",
              "      <td>160.044</td>\n",
              "      <td>4</td>\n",
              "      <td>0.271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Volbeat</td>\n",
              "      <td>A Warrior's Call</td>\n",
              "      <td>0hTiTU0yqthnByyZDD3bcc</td>\n",
              "      <td>62</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>0.374</td>\n",
              "      <td>263080</td>\n",
              "      <td>0.903</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>10</td>\n",
              "      <td>0.2440</td>\n",
              "      <td>-4.490</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>109.118</td>\n",
              "      <td>3</td>\n",
              "      <td>0.429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sick Puppies</td>\n",
              "      <td>You're Going Down</td>\n",
              "      <td>5omWAB5iNMHvbAfBSzkdu8</td>\n",
              "      <td>63</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>5</td>\n",
              "      <td>0.011600</td>\n",
              "      <td>0.488</td>\n",
              "      <td>187347</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.001270</td>\n",
              "      <td>6</td>\n",
              "      <td>0.1460</td>\n",
              "      <td>-5.926</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0469</td>\n",
              "      <td>90.003</td>\n",
              "      <td>4</td>\n",
              "      <td>0.410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Godsmack</td>\n",
              "      <td>Cryin' Like A Bitch!!</td>\n",
              "      <td>4a9i7rCLfPjbS1sNamZeQN</td>\n",
              "      <td>65</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.543</td>\n",
              "      <td>201667</td>\n",
              "      <td>0.808</td>\n",
              "      <td>0.003360</td>\n",
              "      <td>10</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>-5.484</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0407</td>\n",
              "      <td>95.190</td>\n",
              "      <td>4</td>\n",
              "      <td>0.472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Avenged Sevenfold</td>\n",
              "      <td>Welcome to the Family</td>\n",
              "      <td>0jqblvsI9LBY4irmLVqqEO</td>\n",
              "      <td>65</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>7</td>\n",
              "      <td>0.002670</td>\n",
              "      <td>0.567</td>\n",
              "      <td>245573</td>\n",
              "      <td>0.946</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0567</td>\n",
              "      <td>-3.973</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0935</td>\n",
              "      <td>94.985</td>\n",
              "      <td>4</td>\n",
              "      <td>0.699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Disturbed</td>\n",
              "      <td>Down with the Sickness</td>\n",
              "      <td>4ImIJRZNJhNQLLdUFSYJoS</td>\n",
              "      <td>66</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.649</td>\n",
              "      <td>278707</td>\n",
              "      <td>0.896</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>10</td>\n",
              "      <td>0.1020</td>\n",
              "      <td>-2.704</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0560</td>\n",
              "      <td>90.009</td>\n",
              "      <td>4</td>\n",
              "      <td>0.924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LCD Soundsystem</td>\n",
              "      <td>Dance Yrself Clean</td>\n",
              "      <td>2cmRpmO04TLaKPzmAzySYZ</td>\n",
              "      <td>64</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>9</td>\n",
              "      <td>0.005570</td>\n",
              "      <td>0.739</td>\n",
              "      <td>536471</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0400</td>\n",
              "      <td>-9.829</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0622</td>\n",
              "      <td>98.004</td>\n",
              "      <td>4</td>\n",
              "      <td>0.794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         artist_name              track_name  ... time_signature  valence\n",
              "0           Gorillaz      On Melancholy Hill  ...              4    0.578\n",
              "1  Avenged Sevenfold               Nightmare  ...              4    0.233\n",
              "2     The Black Keys         Howlin' for You  ...              4    0.448\n",
              "3    My Darkest Days       Porn Star Dancing  ...              4    0.271\n",
              "4            Volbeat        A Warrior's Call  ...              3    0.429\n",
              "5       Sick Puppies       You're Going Down  ...              4    0.410\n",
              "6           Godsmack   Cryin' Like A Bitch!!  ...              4    0.472\n",
              "7  Avenged Sevenfold   Welcome to the Family  ...              4    0.699\n",
              "8          Disturbed  Down with the Sickness  ...              4    0.924\n",
              "9    LCD Soundsystem      Dance Yrself Clean  ...              4    0.794\n",
              "\n",
              "[10 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keviRNo7xz8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create onehots for the genre column, add them on\n",
        "genreframe = pd.concat([df,pd.get_dummies(df['genre'], prefix='genre')],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7cYOHfLykeM",
        "colab_type": "code",
        "outputId": "d8ee2130-146f-413d-f4ff-8c8a02f05f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "# check\n",
        "genreframe.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist_name</th>\n",
              "      <th>track_name</th>\n",
              "      <th>track_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>year</th>\n",
              "      <th>genre</th>\n",
              "      <th>id</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>key</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>valence</th>\n",
              "      <th>genre_alternative</th>\n",
              "      <th>genre_country</th>\n",
              "      <th>genre_dance</th>\n",
              "      <th>genre_folk</th>\n",
              "      <th>genre_grunge</th>\n",
              "      <th>genre_indie</th>\n",
              "      <th>genre_jazz</th>\n",
              "      <th>genre_metal</th>\n",
              "      <th>genre_pop</th>\n",
              "      <th>genre_punk</th>\n",
              "      <th>genre_rap</th>\n",
              "      <th>genre_rock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gorillaz</td>\n",
              "      <td>On Melancholy Hill</td>\n",
              "      <td>0q6LuUqGLUiCPP1cbdwFs3</td>\n",
              "      <td>75</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.689</td>\n",
              "      <td>233867</td>\n",
              "      <td>0.739</td>\n",
              "      <td>0.509000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0640</td>\n",
              "      <td>-5.810</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>120.423</td>\n",
              "      <td>4</td>\n",
              "      <td>0.578</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Avenged Sevenfold</td>\n",
              "      <td>Nightmare</td>\n",
              "      <td>4UEo1b0wWrtHMC8bVqPiH8</td>\n",
              "      <td>70</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.554</td>\n",
              "      <td>374453</td>\n",
              "      <td>0.949</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>-4.928</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0787</td>\n",
              "      <td>129.984</td>\n",
              "      <td>4</td>\n",
              "      <td>0.233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Black Keys</td>\n",
              "      <td>Howlin' for You</td>\n",
              "      <td>0grFc6klR3hxoHLcgCYsF4</td>\n",
              "      <td>66</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>2</td>\n",
              "      <td>0.028000</td>\n",
              "      <td>0.705</td>\n",
              "      <td>191800</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.078300</td>\n",
              "      <td>11</td>\n",
              "      <td>0.1120</td>\n",
              "      <td>-6.646</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0931</td>\n",
              "      <td>132.627</td>\n",
              "      <td>4</td>\n",
              "      <td>0.448</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My Darkest Days</td>\n",
              "      <td>Porn Star Dancing</td>\n",
              "      <td>3Q8zopc4ABXhysDb1sgLVW</td>\n",
              "      <td>65</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>3</td>\n",
              "      <td>0.013900</td>\n",
              "      <td>0.477</td>\n",
              "      <td>199013</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0756</td>\n",
              "      <td>-3.399</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0837</td>\n",
              "      <td>160.044</td>\n",
              "      <td>4</td>\n",
              "      <td>0.271</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Volbeat</td>\n",
              "      <td>A Warrior's Call</td>\n",
              "      <td>0hTiTU0yqthnByyZDD3bcc</td>\n",
              "      <td>62</td>\n",
              "      <td>2010</td>\n",
              "      <td>alternative</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>0.374</td>\n",
              "      <td>263080</td>\n",
              "      <td>0.903</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>10</td>\n",
              "      <td>0.2440</td>\n",
              "      <td>-4.490</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>109.118</td>\n",
              "      <td>3</td>\n",
              "      <td>0.429</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         artist_name          track_name  ... genre_rap  genre_rock\n",
              "0           Gorillaz  On Melancholy Hill  ...         0           0\n",
              "1  Avenged Sevenfold           Nightmare  ...         0           0\n",
              "2     The Black Keys     Howlin' for You  ...         0           0\n",
              "3    My Darkest Days   Porn Star Dancing  ...         0           0\n",
              "4            Volbeat    A Warrior's Call  ...         0           0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLXpKFMn21FC",
        "colab_type": "code",
        "outputId": "83b28d58-178c-45e9-da6d-9b7cd1fec5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# features to use for genre inference\n",
        "genreframe.iloc[0,7:20]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "acousticness        1.51e-05\n",
              "danceability           0.689\n",
              "duration_ms           233867\n",
              "energy                 0.739\n",
              "instrumentalness       0.509\n",
              "key                        2\n",
              "liveness               0.064\n",
              "loudness               -5.81\n",
              "mode                       1\n",
              "speechiness            0.026\n",
              "tempo                120.423\n",
              "time_signature             4\n",
              "valence                0.578\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XxUNwzqq2sk",
        "colab_type": "code",
        "outputId": "0de83130-a05e-43b4-99d6-528bb196d2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "# get the features for genre inference, scale them.\n",
        "X_train = genreframe.iloc[:,7:20].to_numpy()\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_train)\n",
        "X_scaled"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.81353437,  0.86273319,  0.01422737, ..., -0.07457545,\n",
              "         0.21919423,  0.52020022],\n",
              "       [-0.81253793,  0.02764277,  1.61395879, ...,  0.24680209,\n",
              "         0.21919423, -0.95936143],\n",
              "       [-0.72147348,  0.96170687, -0.46445403, ...,  0.33564226,\n",
              "         0.21919423, -0.03731576],\n",
              "       ...,\n",
              "       [ 0.35424623,  1.02975127,  0.17080273, ..., -0.0196848 ,\n",
              "         0.21919423,  1.42080297],\n",
              "       [-0.80624809, -0.62187201, -1.57989421, ..., -1.07440547,\n",
              "         0.21919423,  1.22781667],\n",
              "       [-0.42211418,  1.23388449, -0.24267685, ..., -0.99696024,\n",
              "         0.21919423, -0.50048289]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsBve5_9Z6Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f57d32d1-63b6-443c-8983-5825ab0fa64e"
      },
      "source": [
        "# pickle the scaler\n",
        "joblib.dump(scaler, 'genre_NN_scaler')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['genre_NN_scaler']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRCoXukYv3bI",
        "colab_type": "code",
        "outputId": "1d5c2679-9314-4495-b51a-61e6084f8bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "# genre list\n",
        "genres = genreframe.genre.unique().tolist()\n",
        "genres"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alternative',\n",
              " 'country',\n",
              " 'dance',\n",
              " 'folk',\n",
              " 'grunge',\n",
              " 'indie',\n",
              " 'jazz',\n",
              " 'metal',\n",
              " 'pop',\n",
              " 'punk',\n",
              " 'rap',\n",
              " 'rock']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fohOUtlQs-0H",
        "colab_type": "code",
        "outputId": "c11d14f7-9a73-44db-d61d-8144317d14c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# get the onehots for targets\n",
        "onehots = genreframe.iloc[:,20:]\n",
        "y_train = onehots.to_numpy()\n",
        "y_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(164449, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XFBrQTyUejP",
        "colab_type": "code",
        "outputId": "1eafc00c-a67c-4caa-d94e-bddf3696a9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "\n",
        "# input\n",
        "model.add(Dense(26, input_dim=13, activation='relu'))\n",
        "# hidden\n",
        "model.add(Dropout(0.2))\n",
        "# hidden\n",
        "model.add(Dense(26, activation='relu'))\n",
        "# hidden\n",
        "model.add(Dropout(0.2))\n",
        "# hidden\n",
        "model.add(Dense(26, activation='relu'))\n",
        "# hidden\n",
        "model.add(Dropout(0.2))\n",
        "# map down to number of classes\n",
        "model.add(Dense(12,activation='relu'))\n",
        "# set the softmax temperature \n",
        "model.add(Lambda(lambda x: x / 10.0))\n",
        "# softmax layer\n",
        "model.add(Softmax())\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "#Compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 26)                364       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 26)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 26)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 26)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 12)                324       \n",
            "_________________________________________________________________\n",
            "lambda_3 (Lambda)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "softmax_3 (Softmax)          (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 2,092\n",
            "Trainable params: 2,092\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwtWcgPxtjQP",
        "colab_type": "code",
        "outputId": "b4d3cb74-7e6f-4562-f698-23f95dfb7a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_scaled, y_train, validation_split=0.2, epochs=1000, batch_size=2048)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 131559 samples, validate on 32890 samples\n",
            "Epoch 1/1000\n",
            "131559/131559 [==============================] - 1s 4us/sample - loss: 2.4644 - acc: 0.1278 - val_loss: 2.4155 - val_acc: 0.1187\n",
            "Epoch 2/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.3398 - acc: 0.1765 - val_loss: 2.2924 - val_acc: 0.1718\n",
            "Epoch 3/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.2155 - acc: 0.2228 - val_loss: 2.1156 - val_acc: 0.2548\n",
            "Epoch 4/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.1166 - acc: 0.2623 - val_loss: 2.0094 - val_acc: 0.3303\n",
            "Epoch 5/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0675 - acc: 0.2854 - val_loss: 1.9705 - val_acc: 0.3483\n",
            "Epoch 6/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0456 - acc: 0.2946 - val_loss: 1.9635 - val_acc: 0.3520\n",
            "Epoch 7/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0336 - acc: 0.3007 - val_loss: 1.9505 - val_acc: 0.3592\n",
            "Epoch 8/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0237 - acc: 0.3033 - val_loss: 1.9434 - val_acc: 0.3609\n",
            "Epoch 9/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0164 - acc: 0.3066 - val_loss: 1.9381 - val_acc: 0.3604\n",
            "Epoch 10/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0106 - acc: 0.3069 - val_loss: 1.9332 - val_acc: 0.3599\n",
            "Epoch 11/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0057 - acc: 0.3097 - val_loss: 1.9266 - val_acc: 0.3621\n",
            "Epoch 12/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 2.0004 - acc: 0.3114 - val_loss: 1.9234 - val_acc: 0.3649\n",
            "Epoch 13/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9952 - acc: 0.3122 - val_loss: 1.9223 - val_acc: 0.3643\n",
            "Epoch 14/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9918 - acc: 0.3133 - val_loss: 1.9150 - val_acc: 0.3670\n",
            "Epoch 15/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9893 - acc: 0.3153 - val_loss: 1.9137 - val_acc: 0.3682\n",
            "Epoch 16/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9869 - acc: 0.3153 - val_loss: 1.9139 - val_acc: 0.3645\n",
            "Epoch 17/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9832 - acc: 0.3163 - val_loss: 1.9119 - val_acc: 0.3685\n",
            "Epoch 18/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9812 - acc: 0.3178 - val_loss: 1.9110 - val_acc: 0.3681\n",
            "Epoch 19/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9794 - acc: 0.3187 - val_loss: 1.9069 - val_acc: 0.3686\n",
            "Epoch 20/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9763 - acc: 0.3191 - val_loss: 1.9113 - val_acc: 0.3662\n",
            "Epoch 21/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9761 - acc: 0.3186 - val_loss: 1.9030 - val_acc: 0.3689\n",
            "Epoch 22/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9736 - acc: 0.3209 - val_loss: 1.9041 - val_acc: 0.3679\n",
            "Epoch 23/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9729 - acc: 0.3200 - val_loss: 1.9059 - val_acc: 0.3688\n",
            "Epoch 24/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9716 - acc: 0.3212 - val_loss: 1.8998 - val_acc: 0.3710\n",
            "Epoch 25/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9711 - acc: 0.3204 - val_loss: 1.9012 - val_acc: 0.3705\n",
            "Epoch 26/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9696 - acc: 0.3205 - val_loss: 1.8951 - val_acc: 0.3726\n",
            "Epoch 27/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9688 - acc: 0.3223 - val_loss: 1.8991 - val_acc: 0.3715\n",
            "Epoch 28/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9640 - acc: 0.3230 - val_loss: 1.8993 - val_acc: 0.3687\n",
            "Epoch 29/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9655 - acc: 0.3224 - val_loss: 1.8971 - val_acc: 0.3710\n",
            "Epoch 30/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9649 - acc: 0.3242 - val_loss: 1.8961 - val_acc: 0.3702\n",
            "Epoch 31/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9625 - acc: 0.3256 - val_loss: 1.8965 - val_acc: 0.3717\n",
            "Epoch 32/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9619 - acc: 0.3231 - val_loss: 1.8940 - val_acc: 0.3729\n",
            "Epoch 33/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9597 - acc: 0.3261 - val_loss: 1.8947 - val_acc: 0.3720\n",
            "Epoch 34/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9596 - acc: 0.3248 - val_loss: 1.8921 - val_acc: 0.3725\n",
            "Epoch 35/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9591 - acc: 0.3242 - val_loss: 1.8927 - val_acc: 0.3715\n",
            "Epoch 36/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9566 - acc: 0.3262 - val_loss: 1.8924 - val_acc: 0.3734\n",
            "Epoch 37/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9554 - acc: 0.3271 - val_loss: 1.8905 - val_acc: 0.3734\n",
            "Epoch 38/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9545 - acc: 0.3277 - val_loss: 1.8856 - val_acc: 0.3758\n",
            "Epoch 39/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9527 - acc: 0.3290 - val_loss: 1.8847 - val_acc: 0.3749\n",
            "Epoch 40/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9536 - acc: 0.3279 - val_loss: 1.8852 - val_acc: 0.3759\n",
            "Epoch 41/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9521 - acc: 0.3280 - val_loss: 1.8862 - val_acc: 0.3742\n",
            "Epoch 42/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9520 - acc: 0.3285 - val_loss: 1.8887 - val_acc: 0.3753\n",
            "Epoch 43/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9503 - acc: 0.3297 - val_loss: 1.8879 - val_acc: 0.3744\n",
            "Epoch 44/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9507 - acc: 0.3285 - val_loss: 1.8851 - val_acc: 0.3758\n",
            "Epoch 45/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9500 - acc: 0.3292 - val_loss: 1.8875 - val_acc: 0.3745\n",
            "Epoch 46/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9489 - acc: 0.3300 - val_loss: 1.8838 - val_acc: 0.3766\n",
            "Epoch 47/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9471 - acc: 0.3309 - val_loss: 1.8823 - val_acc: 0.3772\n",
            "Epoch 48/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9466 - acc: 0.3307 - val_loss: 1.8824 - val_acc: 0.3776\n",
            "Epoch 49/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9488 - acc: 0.3302 - val_loss: 1.8812 - val_acc: 0.3782\n",
            "Epoch 50/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9461 - acc: 0.3318 - val_loss: 1.8820 - val_acc: 0.3780\n",
            "Epoch 51/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9439 - acc: 0.3323 - val_loss: 1.8798 - val_acc: 0.3774\n",
            "Epoch 52/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9439 - acc: 0.3317 - val_loss: 1.8800 - val_acc: 0.3783\n",
            "Epoch 53/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9445 - acc: 0.3323 - val_loss: 1.8787 - val_acc: 0.3782\n",
            "Epoch 54/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9448 - acc: 0.3309 - val_loss: 1.8803 - val_acc: 0.3781\n",
            "Epoch 55/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9453 - acc: 0.3306 - val_loss: 1.8793 - val_acc: 0.3780\n",
            "Epoch 56/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9437 - acc: 0.3308 - val_loss: 1.8761 - val_acc: 0.3792\n",
            "Epoch 57/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9425 - acc: 0.3328 - val_loss: 1.8752 - val_acc: 0.3802\n",
            "Epoch 58/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9406 - acc: 0.3333 - val_loss: 1.8789 - val_acc: 0.3786\n",
            "Epoch 59/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9417 - acc: 0.3332 - val_loss: 1.8756 - val_acc: 0.3787\n",
            "Epoch 60/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9413 - acc: 0.3332 - val_loss: 1.8728 - val_acc: 0.3812\n",
            "Epoch 61/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9382 - acc: 0.3333 - val_loss: 1.8758 - val_acc: 0.3801\n",
            "Epoch 62/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9399 - acc: 0.3339 - val_loss: 1.8760 - val_acc: 0.3796\n",
            "Epoch 63/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9382 - acc: 0.3348 - val_loss: 1.8733 - val_acc: 0.3809\n",
            "Epoch 64/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9390 - acc: 0.3336 - val_loss: 1.8749 - val_acc: 0.3801\n",
            "Epoch 65/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9354 - acc: 0.3352 - val_loss: 1.8740 - val_acc: 0.3811\n",
            "Epoch 66/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.9387 - acc: 0.3336 - val_loss: 1.8729 - val_acc: 0.3809\n",
            "Epoch 67/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9377 - acc: 0.3346 - val_loss: 1.8721 - val_acc: 0.3815\n",
            "Epoch 68/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9361 - acc: 0.3350 - val_loss: 1.8740 - val_acc: 0.3798\n",
            "Epoch 69/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9374 - acc: 0.3345 - val_loss: 1.8728 - val_acc: 0.3810\n",
            "Epoch 70/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9381 - acc: 0.3352 - val_loss: 1.8732 - val_acc: 0.3817\n",
            "Epoch 71/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9353 - acc: 0.3363 - val_loss: 1.8744 - val_acc: 0.3803\n",
            "Epoch 72/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9358 - acc: 0.3355 - val_loss: 1.8741 - val_acc: 0.3801\n",
            "Epoch 73/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9334 - acc: 0.3353 - val_loss: 1.8688 - val_acc: 0.3827\n",
            "Epoch 74/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9322 - acc: 0.3366 - val_loss: 1.8705 - val_acc: 0.3813\n",
            "Epoch 75/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9331 - acc: 0.3365 - val_loss: 1.8703 - val_acc: 0.3810\n",
            "Epoch 76/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9329 - acc: 0.3364 - val_loss: 1.8697 - val_acc: 0.3825\n",
            "Epoch 77/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9315 - acc: 0.3371 - val_loss: 1.8702 - val_acc: 0.3818\n",
            "Epoch 78/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9327 - acc: 0.3373 - val_loss: 1.8711 - val_acc: 0.3818\n",
            "Epoch 79/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9324 - acc: 0.3373 - val_loss: 1.8684 - val_acc: 0.3838\n",
            "Epoch 80/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9310 - acc: 0.3369 - val_loss: 1.8679 - val_acc: 0.3830\n",
            "Epoch 81/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9320 - acc: 0.3376 - val_loss: 1.8688 - val_acc: 0.3829\n",
            "Epoch 82/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9325 - acc: 0.3368 - val_loss: 1.8673 - val_acc: 0.3829\n",
            "Epoch 83/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9319 - acc: 0.3376 - val_loss: 1.8670 - val_acc: 0.3836\n",
            "Epoch 84/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9298 - acc: 0.3376 - val_loss: 1.8675 - val_acc: 0.3814\n",
            "Epoch 85/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9312 - acc: 0.3390 - val_loss: 1.8637 - val_acc: 0.3838\n",
            "Epoch 86/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9298 - acc: 0.3369 - val_loss: 1.8692 - val_acc: 0.3819\n",
            "Epoch 87/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9290 - acc: 0.3382 - val_loss: 1.8690 - val_acc: 0.3822\n",
            "Epoch 88/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9293 - acc: 0.3378 - val_loss: 1.8673 - val_acc: 0.3835\n",
            "Epoch 89/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9293 - acc: 0.3383 - val_loss: 1.8700 - val_acc: 0.3816\n",
            "Epoch 90/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9271 - acc: 0.3383 - val_loss: 1.8671 - val_acc: 0.3832\n",
            "Epoch 91/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9279 - acc: 0.3382 - val_loss: 1.8680 - val_acc: 0.3826\n",
            "Epoch 92/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9266 - acc: 0.3399 - val_loss: 1.8697 - val_acc: 0.3811\n",
            "Epoch 93/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9286 - acc: 0.3369 - val_loss: 1.8669 - val_acc: 0.3831\n",
            "Epoch 94/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9250 - acc: 0.3385 - val_loss: 1.8658 - val_acc: 0.3842\n",
            "Epoch 95/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9261 - acc: 0.3396 - val_loss: 1.8679 - val_acc: 0.3839\n",
            "Epoch 96/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9267 - acc: 0.3399 - val_loss: 1.8677 - val_acc: 0.3833\n",
            "Epoch 97/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9246 - acc: 0.3401 - val_loss: 1.8636 - val_acc: 0.3844\n",
            "Epoch 98/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9261 - acc: 0.3390 - val_loss: 1.8685 - val_acc: 0.3821\n",
            "Epoch 99/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9255 - acc: 0.3400 - val_loss: 1.8631 - val_acc: 0.3843\n",
            "Epoch 100/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9242 - acc: 0.3395 - val_loss: 1.8657 - val_acc: 0.3820\n",
            "Epoch 101/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9254 - acc: 0.3397 - val_loss: 1.8653 - val_acc: 0.3836\n",
            "Epoch 102/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9236 - acc: 0.3404 - val_loss: 1.8634 - val_acc: 0.3832\n",
            "Epoch 103/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9251 - acc: 0.3397 - val_loss: 1.8610 - val_acc: 0.3859\n",
            "Epoch 104/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9237 - acc: 0.3405 - val_loss: 1.8629 - val_acc: 0.3829\n",
            "Epoch 105/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9245 - acc: 0.3418 - val_loss: 1.8633 - val_acc: 0.3840\n",
            "Epoch 106/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9242 - acc: 0.3407 - val_loss: 1.8656 - val_acc: 0.3843\n",
            "Epoch 107/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9212 - acc: 0.3407 - val_loss: 1.8601 - val_acc: 0.3852\n",
            "Epoch 108/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9238 - acc: 0.3407 - val_loss: 1.8621 - val_acc: 0.3853\n",
            "Epoch 109/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9232 - acc: 0.3420 - val_loss: 1.8622 - val_acc: 0.3853\n",
            "Epoch 110/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9243 - acc: 0.3406 - val_loss: 1.8640 - val_acc: 0.3840\n",
            "Epoch 111/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9238 - acc: 0.3412 - val_loss: 1.8635 - val_acc: 0.3839\n",
            "Epoch 112/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9227 - acc: 0.3413 - val_loss: 1.8638 - val_acc: 0.3839\n",
            "Epoch 113/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9214 - acc: 0.3403 - val_loss: 1.8604 - val_acc: 0.3840\n",
            "Epoch 114/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9224 - acc: 0.3404 - val_loss: 1.8616 - val_acc: 0.3836\n",
            "Epoch 115/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9201 - acc: 0.3412 - val_loss: 1.8597 - val_acc: 0.3852\n",
            "Epoch 116/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9218 - acc: 0.3410 - val_loss: 1.8620 - val_acc: 0.3828\n",
            "Epoch 117/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9216 - acc: 0.3416 - val_loss: 1.8635 - val_acc: 0.3816\n",
            "Epoch 118/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9227 - acc: 0.3406 - val_loss: 1.8631 - val_acc: 0.3842\n",
            "Epoch 119/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9196 - acc: 0.3433 - val_loss: 1.8617 - val_acc: 0.3839\n",
            "Epoch 120/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9223 - acc: 0.3402 - val_loss: 1.8620 - val_acc: 0.3834\n",
            "Epoch 121/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9201 - acc: 0.3423 - val_loss: 1.8610 - val_acc: 0.3833\n",
            "Epoch 122/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9195 - acc: 0.3422 - val_loss: 1.8637 - val_acc: 0.3836\n",
            "Epoch 123/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9206 - acc: 0.3409 - val_loss: 1.8602 - val_acc: 0.3848\n",
            "Epoch 124/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.9184 - acc: 0.3421 - val_loss: 1.8591 - val_acc: 0.3858\n",
            "Epoch 125/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9189 - acc: 0.3423 - val_loss: 1.8623 - val_acc: 0.3837\n",
            "Epoch 126/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9202 - acc: 0.3421 - val_loss: 1.8627 - val_acc: 0.3833\n",
            "Epoch 127/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9205 - acc: 0.3409 - val_loss: 1.8624 - val_acc: 0.3836\n",
            "Epoch 128/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9190 - acc: 0.3428 - val_loss: 1.8599 - val_acc: 0.3850\n",
            "Epoch 129/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9182 - acc: 0.3425 - val_loss: 1.8598 - val_acc: 0.3856\n",
            "Epoch 130/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9186 - acc: 0.3428 - val_loss: 1.8580 - val_acc: 0.3856\n",
            "Epoch 131/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9158 - acc: 0.3438 - val_loss: 1.8574 - val_acc: 0.3864\n",
            "Epoch 132/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9173 - acc: 0.3435 - val_loss: 1.8592 - val_acc: 0.3853\n",
            "Epoch 133/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9176 - acc: 0.3436 - val_loss: 1.8590 - val_acc: 0.3853\n",
            "Epoch 134/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9184 - acc: 0.3420 - val_loss: 1.8599 - val_acc: 0.3859\n",
            "Epoch 135/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9176 - acc: 0.3441 - val_loss: 1.8589 - val_acc: 0.3860\n",
            "Epoch 136/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9173 - acc: 0.3447 - val_loss: 1.8609 - val_acc: 0.3851\n",
            "Epoch 137/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9190 - acc: 0.3429 - val_loss: 1.8601 - val_acc: 0.3860\n",
            "Epoch 138/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9171 - acc: 0.3426 - val_loss: 1.8590 - val_acc: 0.3858\n",
            "Epoch 139/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9164 - acc: 0.3438 - val_loss: 1.8575 - val_acc: 0.3857\n",
            "Epoch 140/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9189 - acc: 0.3422 - val_loss: 1.8613 - val_acc: 0.3860\n",
            "Epoch 141/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9158 - acc: 0.3434 - val_loss: 1.8594 - val_acc: 0.3847\n",
            "Epoch 142/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9156 - acc: 0.3438 - val_loss: 1.8591 - val_acc: 0.3859\n",
            "Epoch 143/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9150 - acc: 0.3439 - val_loss: 1.8580 - val_acc: 0.3863\n",
            "Epoch 144/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9167 - acc: 0.3426 - val_loss: 1.8617 - val_acc: 0.3834\n",
            "Epoch 145/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9162 - acc: 0.3425 - val_loss: 1.8598 - val_acc: 0.3854\n",
            "Epoch 146/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9150 - acc: 0.3442 - val_loss: 1.8598 - val_acc: 0.3860\n",
            "Epoch 147/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9159 - acc: 0.3439 - val_loss: 1.8576 - val_acc: 0.3858\n",
            "Epoch 148/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9159 - acc: 0.3436 - val_loss: 1.8603 - val_acc: 0.3863\n",
            "Epoch 149/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9161 - acc: 0.3447 - val_loss: 1.8581 - val_acc: 0.3860\n",
            "Epoch 150/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9165 - acc: 0.3435 - val_loss: 1.8569 - val_acc: 0.3853\n",
            "Epoch 151/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9160 - acc: 0.3448 - val_loss: 1.8602 - val_acc: 0.3848\n",
            "Epoch 152/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9159 - acc: 0.3433 - val_loss: 1.8573 - val_acc: 0.3865\n",
            "Epoch 153/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9165 - acc: 0.3445 - val_loss: 1.8581 - val_acc: 0.3860\n",
            "Epoch 154/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9156 - acc: 0.3435 - val_loss: 1.8584 - val_acc: 0.3857\n",
            "Epoch 155/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9149 - acc: 0.3432 - val_loss: 1.8566 - val_acc: 0.3869\n",
            "Epoch 156/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9144 - acc: 0.3440 - val_loss: 1.8584 - val_acc: 0.3860\n",
            "Epoch 157/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9160 - acc: 0.3435 - val_loss: 1.8599 - val_acc: 0.3852\n",
            "Epoch 158/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9142 - acc: 0.3437 - val_loss: 1.8575 - val_acc: 0.3874\n",
            "Epoch 159/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9146 - acc: 0.3434 - val_loss: 1.8528 - val_acc: 0.3868\n",
            "Epoch 160/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9144 - acc: 0.3442 - val_loss: 1.8570 - val_acc: 0.3860\n",
            "Epoch 161/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9142 - acc: 0.3443 - val_loss: 1.8562 - val_acc: 0.3863\n",
            "Epoch 162/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9140 - acc: 0.3444 - val_loss: 1.8537 - val_acc: 0.3888\n",
            "Epoch 163/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9145 - acc: 0.3436 - val_loss: 1.8561 - val_acc: 0.3874\n",
            "Epoch 164/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9130 - acc: 0.3456 - val_loss: 1.8588 - val_acc: 0.3861\n",
            "Epoch 165/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9124 - acc: 0.3459 - val_loss: 1.8592 - val_acc: 0.3858\n",
            "Epoch 166/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9134 - acc: 0.3462 - val_loss: 1.8565 - val_acc: 0.3858\n",
            "Epoch 167/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9128 - acc: 0.3450 - val_loss: 1.8580 - val_acc: 0.3877\n",
            "Epoch 168/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9152 - acc: 0.3440 - val_loss: 1.8583 - val_acc: 0.3881\n",
            "Epoch 169/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9127 - acc: 0.3444 - val_loss: 1.8603 - val_acc: 0.3862\n",
            "Epoch 170/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9123 - acc: 0.3457 - val_loss: 1.8544 - val_acc: 0.3873\n",
            "Epoch 171/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9126 - acc: 0.3443 - val_loss: 1.8564 - val_acc: 0.3873\n",
            "Epoch 172/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9138 - acc: 0.3443 - val_loss: 1.8575 - val_acc: 0.3872\n",
            "Epoch 173/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9122 - acc: 0.3456 - val_loss: 1.8573 - val_acc: 0.3864\n",
            "Epoch 174/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9135 - acc: 0.3463 - val_loss: 1.8560 - val_acc: 0.3879\n",
            "Epoch 175/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9104 - acc: 0.3445 - val_loss: 1.8565 - val_acc: 0.3869\n",
            "Epoch 176/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9116 - acc: 0.3459 - val_loss: 1.8537 - val_acc: 0.3877\n",
            "Epoch 177/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9137 - acc: 0.3441 - val_loss: 1.8567 - val_acc: 0.3878\n",
            "Epoch 178/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9130 - acc: 0.3440 - val_loss: 1.8566 - val_acc: 0.3874\n",
            "Epoch 179/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9137 - acc: 0.3446 - val_loss: 1.8568 - val_acc: 0.3868\n",
            "Epoch 180/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9125 - acc: 0.3448 - val_loss: 1.8554 - val_acc: 0.3886\n",
            "Epoch 181/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9125 - acc: 0.3456 - val_loss: 1.8553 - val_acc: 0.3874\n",
            "Epoch 182/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9102 - acc: 0.3456 - val_loss: 1.8594 - val_acc: 0.3867\n",
            "Epoch 183/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9120 - acc: 0.3446 - val_loss: 1.8570 - val_acc: 0.3878\n",
            "Epoch 184/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9119 - acc: 0.3449 - val_loss: 1.8575 - val_acc: 0.3873\n",
            "Epoch 185/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9115 - acc: 0.3451 - val_loss: 1.8581 - val_acc: 0.3863\n",
            "Epoch 186/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9107 - acc: 0.3457 - val_loss: 1.8588 - val_acc: 0.3871\n",
            "Epoch 187/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9114 - acc: 0.3476 - val_loss: 1.8576 - val_acc: 0.3870\n",
            "Epoch 188/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9095 - acc: 0.3453 - val_loss: 1.8533 - val_acc: 0.3882\n",
            "Epoch 189/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9116 - acc: 0.3459 - val_loss: 1.8586 - val_acc: 0.3872\n",
            "Epoch 190/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9123 - acc: 0.3450 - val_loss: 1.8573 - val_acc: 0.3876\n",
            "Epoch 191/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9104 - acc: 0.3464 - val_loss: 1.8555 - val_acc: 0.3875\n",
            "Epoch 192/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9117 - acc: 0.3459 - val_loss: 1.8562 - val_acc: 0.3877\n",
            "Epoch 193/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9095 - acc: 0.3461 - val_loss: 1.8555 - val_acc: 0.3876\n",
            "Epoch 194/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9119 - acc: 0.3464 - val_loss: 1.8550 - val_acc: 0.3871\n",
            "Epoch 195/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9111 - acc: 0.3453 - val_loss: 1.8544 - val_acc: 0.3884\n",
            "Epoch 196/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9105 - acc: 0.3456 - val_loss: 1.8534 - val_acc: 0.3891\n",
            "Epoch 197/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9108 - acc: 0.3460 - val_loss: 1.8575 - val_acc: 0.3871\n",
            "Epoch 198/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9098 - acc: 0.3453 - val_loss: 1.8548 - val_acc: 0.3884\n",
            "Epoch 199/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9068 - acc: 0.3457 - val_loss: 1.8554 - val_acc: 0.3881\n",
            "Epoch 200/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9092 - acc: 0.3462 - val_loss: 1.8523 - val_acc: 0.3896\n",
            "Epoch 201/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9094 - acc: 0.3458 - val_loss: 1.8531 - val_acc: 0.3877\n",
            "Epoch 202/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9121 - acc: 0.3461 - val_loss: 1.8551 - val_acc: 0.3882\n",
            "Epoch 203/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9093 - acc: 0.3479 - val_loss: 1.8553 - val_acc: 0.3885\n",
            "Epoch 204/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9096 - acc: 0.3464 - val_loss: 1.8540 - val_acc: 0.3887\n",
            "Epoch 205/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9085 - acc: 0.3450 - val_loss: 1.8553 - val_acc: 0.3882\n",
            "Epoch 206/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9091 - acc: 0.3456 - val_loss: 1.8542 - val_acc: 0.3883\n",
            "Epoch 207/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9096 - acc: 0.3452 - val_loss: 1.8550 - val_acc: 0.3880\n",
            "Epoch 208/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9093 - acc: 0.3459 - val_loss: 1.8580 - val_acc: 0.3882\n",
            "Epoch 209/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9087 - acc: 0.3466 - val_loss: 1.8530 - val_acc: 0.3892\n",
            "Epoch 210/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9100 - acc: 0.3456 - val_loss: 1.8541 - val_acc: 0.3889\n",
            "Epoch 211/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9083 - acc: 0.3470 - val_loss: 1.8549 - val_acc: 0.3888\n",
            "Epoch 212/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9104 - acc: 0.3459 - val_loss: 1.8545 - val_acc: 0.3887\n",
            "Epoch 213/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9100 - acc: 0.3458 - val_loss: 1.8546 - val_acc: 0.3897\n",
            "Epoch 214/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9081 - acc: 0.3469 - val_loss: 1.8551 - val_acc: 0.3884\n",
            "Epoch 215/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9095 - acc: 0.3464 - val_loss: 1.8547 - val_acc: 0.3880\n",
            "Epoch 216/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9086 - acc: 0.3481 - val_loss: 1.8527 - val_acc: 0.3893\n",
            "Epoch 217/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9076 - acc: 0.3460 - val_loss: 1.8540 - val_acc: 0.3902\n",
            "Epoch 218/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9083 - acc: 0.3466 - val_loss: 1.8540 - val_acc: 0.3888\n",
            "Epoch 219/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9089 - acc: 0.3472 - val_loss: 1.8512 - val_acc: 0.3891\n",
            "Epoch 220/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9100 - acc: 0.3451 - val_loss: 1.8534 - val_acc: 0.3887\n",
            "Epoch 221/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9071 - acc: 0.3458 - val_loss: 1.8497 - val_acc: 0.3895\n",
            "Epoch 222/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9106 - acc: 0.3465 - val_loss: 1.8539 - val_acc: 0.3886\n",
            "Epoch 223/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9091 - acc: 0.3470 - val_loss: 1.8534 - val_acc: 0.3889\n",
            "Epoch 224/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9077 - acc: 0.3463 - val_loss: 1.8531 - val_acc: 0.3891\n",
            "Epoch 225/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9074 - acc: 0.3477 - val_loss: 1.8526 - val_acc: 0.3897\n",
            "Epoch 226/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9072 - acc: 0.3467 - val_loss: 1.8542 - val_acc: 0.3887\n",
            "Epoch 227/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9076 - acc: 0.3468 - val_loss: 1.8523 - val_acc: 0.3891\n",
            "Epoch 228/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9087 - acc: 0.3473 - val_loss: 1.8542 - val_acc: 0.3872\n",
            "Epoch 229/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9073 - acc: 0.3465 - val_loss: 1.8520 - val_acc: 0.3889\n",
            "Epoch 230/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9071 - acc: 0.3468 - val_loss: 1.8510 - val_acc: 0.3884\n",
            "Epoch 231/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9091 - acc: 0.3472 - val_loss: 1.8536 - val_acc: 0.3890\n",
            "Epoch 232/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9081 - acc: 0.3475 - val_loss: 1.8543 - val_acc: 0.3878\n",
            "Epoch 233/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9073 - acc: 0.3468 - val_loss: 1.8547 - val_acc: 0.3888\n",
            "Epoch 234/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9072 - acc: 0.3463 - val_loss: 1.8535 - val_acc: 0.3881\n",
            "Epoch 235/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9070 - acc: 0.3477 - val_loss: 1.8542 - val_acc: 0.3888\n",
            "Epoch 236/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9083 - acc: 0.3473 - val_loss: 1.8543 - val_acc: 0.3888\n",
            "Epoch 237/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9069 - acc: 0.3472 - val_loss: 1.8541 - val_acc: 0.3869\n",
            "Epoch 238/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9081 - acc: 0.3477 - val_loss: 1.8518 - val_acc: 0.3887\n",
            "Epoch 239/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9074 - acc: 0.3461 - val_loss: 1.8546 - val_acc: 0.3878\n",
            "Epoch 240/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9064 - acc: 0.3470 - val_loss: 1.8550 - val_acc: 0.3882\n",
            "Epoch 241/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9069 - acc: 0.3469 - val_loss: 1.8524 - val_acc: 0.3884\n",
            "Epoch 242/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9083 - acc: 0.3464 - val_loss: 1.8546 - val_acc: 0.3879\n",
            "Epoch 243/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9087 - acc: 0.3456 - val_loss: 1.8539 - val_acc: 0.3888\n",
            "Epoch 244/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9084 - acc: 0.3460 - val_loss: 1.8513 - val_acc: 0.3899\n",
            "Epoch 245/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9095 - acc: 0.3460 - val_loss: 1.8547 - val_acc: 0.3887\n",
            "Epoch 246/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9076 - acc: 0.3466 - val_loss: 1.8524 - val_acc: 0.3900\n",
            "Epoch 247/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9067 - acc: 0.3462 - val_loss: 1.8552 - val_acc: 0.3881\n",
            "Epoch 248/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9066 - acc: 0.3474 - val_loss: 1.8539 - val_acc: 0.3890\n",
            "Epoch 249/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9071 - acc: 0.3480 - val_loss: 1.8537 - val_acc: 0.3883\n",
            "Epoch 250/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9075 - acc: 0.3475 - val_loss: 1.8536 - val_acc: 0.3888\n",
            "Epoch 251/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9049 - acc: 0.3482 - val_loss: 1.8542 - val_acc: 0.3876\n",
            "Epoch 252/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9076 - acc: 0.3458 - val_loss: 1.8512 - val_acc: 0.3895\n",
            "Epoch 253/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9064 - acc: 0.3478 - val_loss: 1.8555 - val_acc: 0.3882\n",
            "Epoch 254/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9050 - acc: 0.3467 - val_loss: 1.8548 - val_acc: 0.3872\n",
            "Epoch 255/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9065 - acc: 0.3476 - val_loss: 1.8505 - val_acc: 0.3897\n",
            "Epoch 256/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9080 - acc: 0.3460 - val_loss: 1.8519 - val_acc: 0.3889\n",
            "Epoch 257/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9048 - acc: 0.3471 - val_loss: 1.8523 - val_acc: 0.3888\n",
            "Epoch 258/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9048 - acc: 0.3467 - val_loss: 1.8548 - val_acc: 0.3873\n",
            "Epoch 259/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9071 - acc: 0.3468 - val_loss: 1.8528 - val_acc: 0.3881\n",
            "Epoch 260/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9065 - acc: 0.3471 - val_loss: 1.8538 - val_acc: 0.3887\n",
            "Epoch 261/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9074 - acc: 0.3473 - val_loss: 1.8522 - val_acc: 0.3886\n",
            "Epoch 262/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9065 - acc: 0.3477 - val_loss: 1.8521 - val_acc: 0.3893\n",
            "Epoch 263/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9081 - acc: 0.3480 - val_loss: 1.8535 - val_acc: 0.3893\n",
            "Epoch 264/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9034 - acc: 0.3475 - val_loss: 1.8524 - val_acc: 0.3889\n",
            "Epoch 265/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9061 - acc: 0.3474 - val_loss: 1.8501 - val_acc: 0.3891\n",
            "Epoch 266/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9049 - acc: 0.3476 - val_loss: 1.8532 - val_acc: 0.3892\n",
            "Epoch 267/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9065 - acc: 0.3475 - val_loss: 1.8500 - val_acc: 0.3894\n",
            "Epoch 268/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9061 - acc: 0.3466 - val_loss: 1.8517 - val_acc: 0.3882\n",
            "Epoch 269/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9068 - acc: 0.3474 - val_loss: 1.8498 - val_acc: 0.3898\n",
            "Epoch 270/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9069 - acc: 0.3474 - val_loss: 1.8497 - val_acc: 0.3894\n",
            "Epoch 271/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9049 - acc: 0.3474 - val_loss: 1.8498 - val_acc: 0.3883\n",
            "Epoch 272/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9064 - acc: 0.3475 - val_loss: 1.8526 - val_acc: 0.3898\n",
            "Epoch 273/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9045 - acc: 0.3474 - val_loss: 1.8548 - val_acc: 0.3881\n",
            "Epoch 274/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9054 - acc: 0.3473 - val_loss: 1.8509 - val_acc: 0.3896\n",
            "Epoch 275/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9063 - acc: 0.3469 - val_loss: 1.8512 - val_acc: 0.3893\n",
            "Epoch 276/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9064 - acc: 0.3469 - val_loss: 1.8521 - val_acc: 0.3884\n",
            "Epoch 277/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9071 - acc: 0.3475 - val_loss: 1.8511 - val_acc: 0.3891\n",
            "Epoch 278/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9068 - acc: 0.3476 - val_loss: 1.8519 - val_acc: 0.3879\n",
            "Epoch 279/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9063 - acc: 0.3477 - val_loss: 1.8529 - val_acc: 0.3879\n",
            "Epoch 280/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9052 - acc: 0.3472 - val_loss: 1.8510 - val_acc: 0.3897\n",
            "Epoch 281/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9063 - acc: 0.3471 - val_loss: 1.8535 - val_acc: 0.3877\n",
            "Epoch 282/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9048 - acc: 0.3479 - val_loss: 1.8511 - val_acc: 0.3887\n",
            "Epoch 283/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9053 - acc: 0.3474 - val_loss: 1.8499 - val_acc: 0.3882\n",
            "Epoch 284/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9022 - acc: 0.3480 - val_loss: 1.8488 - val_acc: 0.3878\n",
            "Epoch 285/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9067 - acc: 0.3474 - val_loss: 1.8496 - val_acc: 0.3891\n",
            "Epoch 286/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9047 - acc: 0.3471 - val_loss: 1.8527 - val_acc: 0.3894\n",
            "Epoch 287/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9063 - acc: 0.3480 - val_loss: 1.8501 - val_acc: 0.3896\n",
            "Epoch 288/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9049 - acc: 0.3469 - val_loss: 1.8491 - val_acc: 0.3899\n",
            "Epoch 289/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9049 - acc: 0.3473 - val_loss: 1.8523 - val_acc: 0.3885\n",
            "Epoch 290/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9049 - acc: 0.3478 - val_loss: 1.8531 - val_acc: 0.3890\n",
            "Epoch 291/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9046 - acc: 0.3470 - val_loss: 1.8517 - val_acc: 0.3886\n",
            "Epoch 292/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9058 - acc: 0.3491 - val_loss: 1.8527 - val_acc: 0.3890\n",
            "Epoch 293/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9057 - acc: 0.3483 - val_loss: 1.8488 - val_acc: 0.3899\n",
            "Epoch 294/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9036 - acc: 0.3492 - val_loss: 1.8498 - val_acc: 0.3891\n",
            "Epoch 295/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9025 - acc: 0.3492 - val_loss: 1.8501 - val_acc: 0.3892\n",
            "Epoch 296/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9030 - acc: 0.3491 - val_loss: 1.8504 - val_acc: 0.3893\n",
            "Epoch 297/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9033 - acc: 0.3479 - val_loss: 1.8553 - val_acc: 0.3882\n",
            "Epoch 298/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9031 - acc: 0.3478 - val_loss: 1.8498 - val_acc: 0.3891\n",
            "Epoch 299/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9043 - acc: 0.3484 - val_loss: 1.8516 - val_acc: 0.3885\n",
            "Epoch 300/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9047 - acc: 0.3476 - val_loss: 1.8512 - val_acc: 0.3901\n",
            "Epoch 301/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9041 - acc: 0.3471 - val_loss: 1.8512 - val_acc: 0.3890\n",
            "Epoch 302/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9045 - acc: 0.3473 - val_loss: 1.8507 - val_acc: 0.3891\n",
            "Epoch 303/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9040 - acc: 0.3493 - val_loss: 1.8517 - val_acc: 0.3884\n",
            "Epoch 304/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9044 - acc: 0.3480 - val_loss: 1.8499 - val_acc: 0.3898\n",
            "Epoch 305/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9053 - acc: 0.3480 - val_loss: 1.8518 - val_acc: 0.3899\n",
            "Epoch 306/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9043 - acc: 0.3486 - val_loss: 1.8527 - val_acc: 0.3894\n",
            "Epoch 307/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9026 - acc: 0.3477 - val_loss: 1.8478 - val_acc: 0.3903\n",
            "Epoch 308/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9026 - acc: 0.3491 - val_loss: 1.8479 - val_acc: 0.3905\n",
            "Epoch 309/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9039 - acc: 0.3474 - val_loss: 1.8515 - val_acc: 0.3891\n",
            "Epoch 310/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9034 - acc: 0.3485 - val_loss: 1.8506 - val_acc: 0.3897\n",
            "Epoch 311/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9030 - acc: 0.3482 - val_loss: 1.8506 - val_acc: 0.3883\n",
            "Epoch 312/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9044 - acc: 0.3471 - val_loss: 1.8520 - val_acc: 0.3894\n",
            "Epoch 313/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9016 - acc: 0.3487 - val_loss: 1.8491 - val_acc: 0.3899\n",
            "Epoch 314/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9036 - acc: 0.3474 - val_loss: 1.8526 - val_acc: 0.3894\n",
            "Epoch 315/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9048 - acc: 0.3481 - val_loss: 1.8501 - val_acc: 0.3897\n",
            "Epoch 316/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9029 - acc: 0.3484 - val_loss: 1.8503 - val_acc: 0.3887\n",
            "Epoch 317/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9032 - acc: 0.3482 - val_loss: 1.8522 - val_acc: 0.3893\n",
            "Epoch 318/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9028 - acc: 0.3480 - val_loss: 1.8500 - val_acc: 0.3894\n",
            "Epoch 319/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9035 - acc: 0.3493 - val_loss: 1.8508 - val_acc: 0.3882\n",
            "Epoch 320/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9047 - acc: 0.3476 - val_loss: 1.8516 - val_acc: 0.3890\n",
            "Epoch 321/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9037 - acc: 0.3469 - val_loss: 1.8485 - val_acc: 0.3889\n",
            "Epoch 322/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9021 - acc: 0.3486 - val_loss: 1.8483 - val_acc: 0.3916\n",
            "Epoch 323/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9031 - acc: 0.3486 - val_loss: 1.8482 - val_acc: 0.3900\n",
            "Epoch 324/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9029 - acc: 0.3482 - val_loss: 1.8485 - val_acc: 0.3896\n",
            "Epoch 325/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9039 - acc: 0.3471 - val_loss: 1.8493 - val_acc: 0.3898\n",
            "Epoch 326/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9042 - acc: 0.3485 - val_loss: 1.8506 - val_acc: 0.3892\n",
            "Epoch 327/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9038 - acc: 0.3470 - val_loss: 1.8516 - val_acc: 0.3901\n",
            "Epoch 328/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.9044 - acc: 0.3485 - val_loss: 1.8499 - val_acc: 0.3890\n",
            "Epoch 329/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.9024 - acc: 0.3472 - val_loss: 1.8510 - val_acc: 0.3892\n",
            "Epoch 330/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9040 - acc: 0.3487 - val_loss: 1.8501 - val_acc: 0.3894\n",
            "Epoch 331/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9028 - acc: 0.3483 - val_loss: 1.8507 - val_acc: 0.3889\n",
            "Epoch 332/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9026 - acc: 0.3480 - val_loss: 1.8488 - val_acc: 0.3903\n",
            "Epoch 333/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9025 - acc: 0.3489 - val_loss: 1.8479 - val_acc: 0.3900\n",
            "Epoch 334/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9024 - acc: 0.3485 - val_loss: 1.8503 - val_acc: 0.3905\n",
            "Epoch 335/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9041 - acc: 0.3467 - val_loss: 1.8516 - val_acc: 0.3895\n",
            "Epoch 336/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9031 - acc: 0.3492 - val_loss: 1.8482 - val_acc: 0.3895\n",
            "Epoch 337/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9032 - acc: 0.3472 - val_loss: 1.8506 - val_acc: 0.3899\n",
            "Epoch 338/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9044 - acc: 0.3490 - val_loss: 1.8498 - val_acc: 0.3903\n",
            "Epoch 339/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9050 - acc: 0.3469 - val_loss: 1.8490 - val_acc: 0.3903\n",
            "Epoch 340/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3481 - val_loss: 1.8494 - val_acc: 0.3907\n",
            "Epoch 341/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9036 - acc: 0.3475 - val_loss: 1.8479 - val_acc: 0.3906\n",
            "Epoch 342/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9048 - acc: 0.3471 - val_loss: 1.8495 - val_acc: 0.3898\n",
            "Epoch 343/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9038 - acc: 0.3469 - val_loss: 1.8493 - val_acc: 0.3896\n",
            "Epoch 344/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9035 - acc: 0.3477 - val_loss: 1.8524 - val_acc: 0.3893\n",
            "Epoch 345/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9038 - acc: 0.3477 - val_loss: 1.8492 - val_acc: 0.3900\n",
            "Epoch 346/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9044 - acc: 0.3473 - val_loss: 1.8500 - val_acc: 0.3897\n",
            "Epoch 347/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9045 - acc: 0.3486 - val_loss: 1.8472 - val_acc: 0.3912\n",
            "Epoch 348/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9029 - acc: 0.3477 - val_loss: 1.8500 - val_acc: 0.3893\n",
            "Epoch 349/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9043 - acc: 0.3476 - val_loss: 1.8483 - val_acc: 0.3903\n",
            "Epoch 350/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9026 - acc: 0.3479 - val_loss: 1.8482 - val_acc: 0.3906\n",
            "Epoch 351/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9015 - acc: 0.3470 - val_loss: 1.8473 - val_acc: 0.3906\n",
            "Epoch 352/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9052 - acc: 0.3475 - val_loss: 1.8458 - val_acc: 0.3912\n",
            "Epoch 353/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9030 - acc: 0.3472 - val_loss: 1.8478 - val_acc: 0.3915\n",
            "Epoch 354/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9013 - acc: 0.3491 - val_loss: 1.8487 - val_acc: 0.3907\n",
            "Epoch 355/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9028 - acc: 0.3493 - val_loss: 1.8496 - val_acc: 0.3890\n",
            "Epoch 356/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9020 - acc: 0.3480 - val_loss: 1.8482 - val_acc: 0.3899\n",
            "Epoch 357/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9020 - acc: 0.3475 - val_loss: 1.8487 - val_acc: 0.3908\n",
            "Epoch 358/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9021 - acc: 0.3481 - val_loss: 1.8494 - val_acc: 0.3898\n",
            "Epoch 359/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9042 - acc: 0.3483 - val_loss: 1.8520 - val_acc: 0.3888\n",
            "Epoch 360/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3488 - val_loss: 1.8461 - val_acc: 0.3905\n",
            "Epoch 361/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9017 - acc: 0.3466 - val_loss: 1.8480 - val_acc: 0.3915\n",
            "Epoch 362/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9023 - acc: 0.3480 - val_loss: 1.8483 - val_acc: 0.3910\n",
            "Epoch 363/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9024 - acc: 0.3478 - val_loss: 1.8502 - val_acc: 0.3904\n",
            "Epoch 364/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3488 - val_loss: 1.8518 - val_acc: 0.3899\n",
            "Epoch 365/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9019 - acc: 0.3498 - val_loss: 1.8449 - val_acc: 0.3913\n",
            "Epoch 366/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9036 - acc: 0.3476 - val_loss: 1.8502 - val_acc: 0.3915\n",
            "Epoch 367/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9019 - acc: 0.3472 - val_loss: 1.8481 - val_acc: 0.3910\n",
            "Epoch 368/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3483 - val_loss: 1.8480 - val_acc: 0.3910\n",
            "Epoch 369/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9025 - acc: 0.3472 - val_loss: 1.8474 - val_acc: 0.3913\n",
            "Epoch 370/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9028 - acc: 0.3480 - val_loss: 1.8497 - val_acc: 0.3900\n",
            "Epoch 371/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9009 - acc: 0.3481 - val_loss: 1.8490 - val_acc: 0.3905\n",
            "Epoch 372/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9010 - acc: 0.3476 - val_loss: 1.8467 - val_acc: 0.3914\n",
            "Epoch 373/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9019 - acc: 0.3489 - val_loss: 1.8482 - val_acc: 0.3896\n",
            "Epoch 374/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3483 - val_loss: 1.8474 - val_acc: 0.3913\n",
            "Epoch 375/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9001 - acc: 0.3484 - val_loss: 1.8475 - val_acc: 0.3899\n",
            "Epoch 376/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9015 - acc: 0.3486 - val_loss: 1.8476 - val_acc: 0.3905\n",
            "Epoch 377/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9024 - acc: 0.3492 - val_loss: 1.8481 - val_acc: 0.3901\n",
            "Epoch 378/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3478 - val_loss: 1.8494 - val_acc: 0.3910\n",
            "Epoch 379/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9028 - acc: 0.3468 - val_loss: 1.8466 - val_acc: 0.3900\n",
            "Epoch 380/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9021 - acc: 0.3486 - val_loss: 1.8476 - val_acc: 0.3899\n",
            "Epoch 381/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9025 - acc: 0.3491 - val_loss: 1.8468 - val_acc: 0.3914\n",
            "Epoch 382/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3487 - val_loss: 1.8478 - val_acc: 0.3914\n",
            "Epoch 383/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9035 - acc: 0.3485 - val_loss: 1.8476 - val_acc: 0.3907\n",
            "Epoch 384/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9007 - acc: 0.3487 - val_loss: 1.8494 - val_acc: 0.3906\n",
            "Epoch 385/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9026 - acc: 0.3492 - val_loss: 1.8468 - val_acc: 0.3906\n",
            "Epoch 386/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9009 - acc: 0.3484 - val_loss: 1.8493 - val_acc: 0.3904\n",
            "Epoch 387/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9017 - acc: 0.3480 - val_loss: 1.8465 - val_acc: 0.3909\n",
            "Epoch 388/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9021 - acc: 0.3474 - val_loss: 1.8488 - val_acc: 0.3895\n",
            "Epoch 389/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9013 - acc: 0.3480 - val_loss: 1.8479 - val_acc: 0.3904\n",
            "Epoch 390/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9015 - acc: 0.3485 - val_loss: 1.8461 - val_acc: 0.3912\n",
            "Epoch 391/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3490 - val_loss: 1.8484 - val_acc: 0.3917\n",
            "Epoch 392/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3481 - val_loss: 1.8486 - val_acc: 0.3894\n",
            "Epoch 393/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9019 - acc: 0.3485 - val_loss: 1.8471 - val_acc: 0.3905\n",
            "Epoch 394/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3486 - val_loss: 1.8467 - val_acc: 0.3905\n",
            "Epoch 395/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3481 - val_loss: 1.8511 - val_acc: 0.3899\n",
            "Epoch 396/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9039 - acc: 0.3479 - val_loss: 1.8449 - val_acc: 0.3915\n",
            "Epoch 397/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3473 - val_loss: 1.8477 - val_acc: 0.3896\n",
            "Epoch 398/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9016 - acc: 0.3481 - val_loss: 1.8484 - val_acc: 0.3908\n",
            "Epoch 399/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9005 - acc: 0.3488 - val_loss: 1.8517 - val_acc: 0.3885\n",
            "Epoch 400/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9002 - acc: 0.3488 - val_loss: 1.8467 - val_acc: 0.3897\n",
            "Epoch 401/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3482 - val_loss: 1.8484 - val_acc: 0.3906\n",
            "Epoch 402/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9024 - acc: 0.3482 - val_loss: 1.8464 - val_acc: 0.3906\n",
            "Epoch 403/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9029 - acc: 0.3481 - val_loss: 1.8468 - val_acc: 0.3906\n",
            "Epoch 404/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9024 - acc: 0.3486 - val_loss: 1.8458 - val_acc: 0.3902\n",
            "Epoch 405/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3503 - val_loss: 1.8472 - val_acc: 0.3897\n",
            "Epoch 406/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3492 - val_loss: 1.8489 - val_acc: 0.3900\n",
            "Epoch 407/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3493 - val_loss: 1.8458 - val_acc: 0.3918\n",
            "Epoch 408/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3489 - val_loss: 1.8472 - val_acc: 0.3898\n",
            "Epoch 409/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3508 - val_loss: 1.8502 - val_acc: 0.3904\n",
            "Epoch 410/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9022 - acc: 0.3478 - val_loss: 1.8494 - val_acc: 0.3902\n",
            "Epoch 411/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8996 - acc: 0.3500 - val_loss: 1.8476 - val_acc: 0.3903\n",
            "Epoch 412/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3477 - val_loss: 1.8471 - val_acc: 0.3908\n",
            "Epoch 413/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9021 - acc: 0.3476 - val_loss: 1.8470 - val_acc: 0.3903\n",
            "Epoch 414/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3486 - val_loss: 1.8467 - val_acc: 0.3923\n",
            "Epoch 415/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8990 - acc: 0.3486 - val_loss: 1.8488 - val_acc: 0.3895\n",
            "Epoch 416/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9023 - acc: 0.3485 - val_loss: 1.8471 - val_acc: 0.3914\n",
            "Epoch 417/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3494 - val_loss: 1.8498 - val_acc: 0.3896\n",
            "Epoch 418/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9030 - acc: 0.3480 - val_loss: 1.8454 - val_acc: 0.3910\n",
            "Epoch 419/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3490 - val_loss: 1.8472 - val_acc: 0.3911\n",
            "Epoch 420/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3487 - val_loss: 1.8492 - val_acc: 0.3902\n",
            "Epoch 421/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9015 - acc: 0.3489 - val_loss: 1.8483 - val_acc: 0.3913\n",
            "Epoch 422/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3485 - val_loss: 1.8454 - val_acc: 0.3915\n",
            "Epoch 423/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9002 - acc: 0.3478 - val_loss: 1.8476 - val_acc: 0.3908\n",
            "Epoch 424/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3489 - val_loss: 1.8441 - val_acc: 0.3916\n",
            "Epoch 425/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3472 - val_loss: 1.8438 - val_acc: 0.3908\n",
            "Epoch 426/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3495 - val_loss: 1.8481 - val_acc: 0.3904\n",
            "Epoch 427/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3483 - val_loss: 1.8479 - val_acc: 0.3898\n",
            "Epoch 428/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8994 - acc: 0.3498 - val_loss: 1.8449 - val_acc: 0.3906\n",
            "Epoch 429/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3487 - val_loss: 1.8472 - val_acc: 0.3896\n",
            "Epoch 430/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9021 - acc: 0.3481 - val_loss: 1.8460 - val_acc: 0.3905\n",
            "Epoch 431/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3480 - val_loss: 1.8491 - val_acc: 0.3896\n",
            "Epoch 432/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9032 - acc: 0.3489 - val_loss: 1.8457 - val_acc: 0.3899\n",
            "Epoch 433/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3489 - val_loss: 1.8479 - val_acc: 0.3905\n",
            "Epoch 434/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9031 - acc: 0.3474 - val_loss: 1.8500 - val_acc: 0.3896\n",
            "Epoch 435/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9025 - acc: 0.3486 - val_loss: 1.8487 - val_acc: 0.3898\n",
            "Epoch 436/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3478 - val_loss: 1.8466 - val_acc: 0.3901\n",
            "Epoch 437/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9002 - acc: 0.3472 - val_loss: 1.8428 - val_acc: 0.3916\n",
            "Epoch 438/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9023 - acc: 0.3488 - val_loss: 1.8465 - val_acc: 0.3900\n",
            "Epoch 439/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9026 - acc: 0.3470 - val_loss: 1.8469 - val_acc: 0.3908\n",
            "Epoch 440/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3472 - val_loss: 1.8479 - val_acc: 0.3899\n",
            "Epoch 441/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9024 - acc: 0.3472 - val_loss: 1.8453 - val_acc: 0.3913\n",
            "Epoch 442/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3486 - val_loss: 1.8494 - val_acc: 0.3909\n",
            "Epoch 443/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3490 - val_loss: 1.8451 - val_acc: 0.3907\n",
            "Epoch 444/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9004 - acc: 0.3477 - val_loss: 1.8482 - val_acc: 0.3902\n",
            "Epoch 445/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9005 - acc: 0.3484 - val_loss: 1.8469 - val_acc: 0.3900\n",
            "Epoch 446/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9018 - acc: 0.3492 - val_loss: 1.8476 - val_acc: 0.3906\n",
            "Epoch 447/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8997 - acc: 0.3491 - val_loss: 1.8467 - val_acc: 0.3908\n",
            "Epoch 448/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8993 - acc: 0.3486 - val_loss: 1.8450 - val_acc: 0.3921\n",
            "Epoch 449/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8996 - acc: 0.3487 - val_loss: 1.8475 - val_acc: 0.3914\n",
            "Epoch 450/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3486 - val_loss: 1.8473 - val_acc: 0.3910\n",
            "Epoch 451/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3498 - val_loss: 1.8471 - val_acc: 0.3901\n",
            "Epoch 452/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3482 - val_loss: 1.8488 - val_acc: 0.3903\n",
            "Epoch 453/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3480 - val_loss: 1.8464 - val_acc: 0.3912\n",
            "Epoch 454/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9005 - acc: 0.3480 - val_loss: 1.8500 - val_acc: 0.3911\n",
            "Epoch 455/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3488 - val_loss: 1.8452 - val_acc: 0.3907\n",
            "Epoch 456/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9000 - acc: 0.3473 - val_loss: 1.8473 - val_acc: 0.3919\n",
            "Epoch 457/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3479 - val_loss: 1.8458 - val_acc: 0.3916\n",
            "Epoch 458/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9002 - acc: 0.3489 - val_loss: 1.8479 - val_acc: 0.3910\n",
            "Epoch 459/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3481 - val_loss: 1.8468 - val_acc: 0.3915\n",
            "Epoch 460/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3495 - val_loss: 1.8479 - val_acc: 0.3911\n",
            "Epoch 461/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3469 - val_loss: 1.8448 - val_acc: 0.3916\n",
            "Epoch 462/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3492 - val_loss: 1.8449 - val_acc: 0.3912\n",
            "Epoch 463/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8997 - acc: 0.3490 - val_loss: 1.8467 - val_acc: 0.3914\n",
            "Epoch 464/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3488 - val_loss: 1.8479 - val_acc: 0.3895\n",
            "Epoch 465/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9000 - acc: 0.3492 - val_loss: 1.8460 - val_acc: 0.3908\n",
            "Epoch 466/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3485 - val_loss: 1.8438 - val_acc: 0.3924\n",
            "Epoch 467/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3501 - val_loss: 1.8465 - val_acc: 0.3909\n",
            "Epoch 468/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3480 - val_loss: 1.8478 - val_acc: 0.3896\n",
            "Epoch 469/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3485 - val_loss: 1.8495 - val_acc: 0.3905\n",
            "Epoch 470/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8993 - acc: 0.3489 - val_loss: 1.8456 - val_acc: 0.3903\n",
            "Epoch 471/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3491 - val_loss: 1.8460 - val_acc: 0.3895\n",
            "Epoch 472/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3482 - val_loss: 1.8474 - val_acc: 0.3901\n",
            "Epoch 473/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9004 - acc: 0.3489 - val_loss: 1.8483 - val_acc: 0.3900\n",
            "Epoch 474/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3492 - val_loss: 1.8493 - val_acc: 0.3899\n",
            "Epoch 475/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9023 - acc: 0.3471 - val_loss: 1.8466 - val_acc: 0.3916\n",
            "Epoch 476/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8989 - acc: 0.3491 - val_loss: 1.8460 - val_acc: 0.3906\n",
            "Epoch 477/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9012 - acc: 0.3475 - val_loss: 1.8489 - val_acc: 0.3904\n",
            "Epoch 478/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9011 - acc: 0.3483 - val_loss: 1.8464 - val_acc: 0.3913\n",
            "Epoch 479/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9001 - acc: 0.3480 - val_loss: 1.8468 - val_acc: 0.3911\n",
            "Epoch 480/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9017 - acc: 0.3464 - val_loss: 1.8484 - val_acc: 0.3902\n",
            "Epoch 481/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8991 - acc: 0.3485 - val_loss: 1.8453 - val_acc: 0.3902\n",
            "Epoch 482/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8990 - acc: 0.3482 - val_loss: 1.8460 - val_acc: 0.3915\n",
            "Epoch 483/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3501 - val_loss: 1.8464 - val_acc: 0.3909\n",
            "Epoch 484/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9016 - acc: 0.3481 - val_loss: 1.8475 - val_acc: 0.3904\n",
            "Epoch 485/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8993 - acc: 0.3478 - val_loss: 1.8459 - val_acc: 0.3912\n",
            "Epoch 486/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8993 - acc: 0.3491 - val_loss: 1.8510 - val_acc: 0.3897\n",
            "Epoch 487/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8990 - acc: 0.3494 - val_loss: 1.8466 - val_acc: 0.3910\n",
            "Epoch 488/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9010 - acc: 0.3487 - val_loss: 1.8489 - val_acc: 0.3909\n",
            "Epoch 489/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9004 - acc: 0.3474 - val_loss: 1.8484 - val_acc: 0.3900\n",
            "Epoch 490/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8998 - acc: 0.3497 - val_loss: 1.8499 - val_acc: 0.3895\n",
            "Epoch 491/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9006 - acc: 0.3478 - val_loss: 1.8482 - val_acc: 0.3906\n",
            "Epoch 492/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8987 - acc: 0.3483 - val_loss: 1.8484 - val_acc: 0.3903\n",
            "Epoch 493/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3481 - val_loss: 1.8458 - val_acc: 0.3898\n",
            "Epoch 494/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3488 - val_loss: 1.8473 - val_acc: 0.3910\n",
            "Epoch 495/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8995 - acc: 0.3481 - val_loss: 1.8463 - val_acc: 0.3902\n",
            "Epoch 496/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3487 - val_loss: 1.8466 - val_acc: 0.3908\n",
            "Epoch 497/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3487 - val_loss: 1.8450 - val_acc: 0.3920\n",
            "Epoch 498/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3484 - val_loss: 1.8470 - val_acc: 0.3919\n",
            "Epoch 499/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9014 - acc: 0.3487 - val_loss: 1.8460 - val_acc: 0.3927\n",
            "Epoch 500/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9004 - acc: 0.3478 - val_loss: 1.8480 - val_acc: 0.3915\n",
            "Epoch 501/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3495 - val_loss: 1.8463 - val_acc: 0.3905\n",
            "Epoch 502/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3481 - val_loss: 1.8463 - val_acc: 0.3907\n",
            "Epoch 503/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3508 - val_loss: 1.8432 - val_acc: 0.3922\n",
            "Epoch 504/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9013 - acc: 0.3477 - val_loss: 1.8471 - val_acc: 0.3914\n",
            "Epoch 505/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9000 - acc: 0.3489 - val_loss: 1.8444 - val_acc: 0.3921\n",
            "Epoch 506/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8997 - acc: 0.3475 - val_loss: 1.8480 - val_acc: 0.3907\n",
            "Epoch 507/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8995 - acc: 0.3486 - val_loss: 1.8468 - val_acc: 0.3903\n",
            "Epoch 508/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8990 - acc: 0.3481 - val_loss: 1.8488 - val_acc: 0.3905\n",
            "Epoch 509/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3482 - val_loss: 1.8469 - val_acc: 0.3901\n",
            "Epoch 510/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8987 - acc: 0.3483 - val_loss: 1.8471 - val_acc: 0.3905\n",
            "Epoch 511/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3475 - val_loss: 1.8477 - val_acc: 0.3917\n",
            "Epoch 512/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3505 - val_loss: 1.8442 - val_acc: 0.3913\n",
            "Epoch 513/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8995 - acc: 0.3493 - val_loss: 1.8460 - val_acc: 0.3916\n",
            "Epoch 514/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8997 - acc: 0.3488 - val_loss: 1.8438 - val_acc: 0.3919\n",
            "Epoch 515/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3495 - val_loss: 1.8442 - val_acc: 0.3925\n",
            "Epoch 516/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8991 - acc: 0.3501 - val_loss: 1.8486 - val_acc: 0.3906\n",
            "Epoch 517/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3497 - val_loss: 1.8453 - val_acc: 0.3919\n",
            "Epoch 518/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9004 - acc: 0.3484 - val_loss: 1.8482 - val_acc: 0.3915\n",
            "Epoch 519/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3494 - val_loss: 1.8462 - val_acc: 0.3909\n",
            "Epoch 520/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8991 - acc: 0.3492 - val_loss: 1.8468 - val_acc: 0.3900\n",
            "Epoch 521/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3483 - val_loss: 1.8462 - val_acc: 0.3912\n",
            "Epoch 522/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3483 - val_loss: 1.8477 - val_acc: 0.3921\n",
            "Epoch 523/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3491 - val_loss: 1.8476 - val_acc: 0.3914\n",
            "Epoch 524/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9008 - acc: 0.3493 - val_loss: 1.8468 - val_acc: 0.3910\n",
            "Epoch 525/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3490 - val_loss: 1.8458 - val_acc: 0.3922\n",
            "Epoch 526/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3501 - val_loss: 1.8447 - val_acc: 0.3916\n",
            "Epoch 527/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3488 - val_loss: 1.8468 - val_acc: 0.3921\n",
            "Epoch 528/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8996 - acc: 0.3490 - val_loss: 1.8430 - val_acc: 0.3924\n",
            "Epoch 529/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9002 - acc: 0.3491 - val_loss: 1.8443 - val_acc: 0.3922\n",
            "Epoch 530/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8987 - acc: 0.3495 - val_loss: 1.8474 - val_acc: 0.3910\n",
            "Epoch 531/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8997 - acc: 0.3484 - val_loss: 1.8480 - val_acc: 0.3914\n",
            "Epoch 532/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3484 - val_loss: 1.8462 - val_acc: 0.3909\n",
            "Epoch 533/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8988 - acc: 0.3486 - val_loss: 1.8483 - val_acc: 0.3910\n",
            "Epoch 534/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.8997 - acc: 0.3484 - val_loss: 1.8427 - val_acc: 0.3926\n",
            "Epoch 535/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3500 - val_loss: 1.8481 - val_acc: 0.3910\n",
            "Epoch 536/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3479 - val_loss: 1.8458 - val_acc: 0.3916\n",
            "Epoch 537/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3497 - val_loss: 1.8455 - val_acc: 0.3922\n",
            "Epoch 538/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8984 - acc: 0.3492 - val_loss: 1.8449 - val_acc: 0.3918\n",
            "Epoch 539/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9000 - acc: 0.3493 - val_loss: 1.8486 - val_acc: 0.3906\n",
            "Epoch 540/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8989 - acc: 0.3485 - val_loss: 1.8440 - val_acc: 0.3926\n",
            "Epoch 541/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3496 - val_loss: 1.8447 - val_acc: 0.3919\n",
            "Epoch 542/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8997 - acc: 0.3493 - val_loss: 1.8456 - val_acc: 0.3916\n",
            "Epoch 543/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8991 - acc: 0.3485 - val_loss: 1.8438 - val_acc: 0.3934\n",
            "Epoch 544/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3499 - val_loss: 1.8441 - val_acc: 0.3924\n",
            "Epoch 545/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3499 - val_loss: 1.8488 - val_acc: 0.3912\n",
            "Epoch 546/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3482 - val_loss: 1.8458 - val_acc: 0.3912\n",
            "Epoch 547/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3491 - val_loss: 1.8465 - val_acc: 0.3918\n",
            "Epoch 548/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9001 - acc: 0.3489 - val_loss: 1.8445 - val_acc: 0.3913\n",
            "Epoch 549/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8998 - acc: 0.3493 - val_loss: 1.8461 - val_acc: 0.3905\n",
            "Epoch 550/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3485 - val_loss: 1.8476 - val_acc: 0.3917\n",
            "Epoch 551/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3502 - val_loss: 1.8444 - val_acc: 0.3917\n",
            "Epoch 552/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3488 - val_loss: 1.8476 - val_acc: 0.3916\n",
            "Epoch 553/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3489 - val_loss: 1.8439 - val_acc: 0.3926\n",
            "Epoch 554/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3497 - val_loss: 1.8484 - val_acc: 0.3900\n",
            "Epoch 555/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3484 - val_loss: 1.8442 - val_acc: 0.3920\n",
            "Epoch 556/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8993 - acc: 0.3490 - val_loss: 1.8449 - val_acc: 0.3929\n",
            "Epoch 557/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3498 - val_loss: 1.8464 - val_acc: 0.3908\n",
            "Epoch 558/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9003 - acc: 0.3481 - val_loss: 1.8491 - val_acc: 0.3914\n",
            "Epoch 559/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8984 - acc: 0.3493 - val_loss: 1.8461 - val_acc: 0.3918\n",
            "Epoch 560/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3492 - val_loss: 1.8459 - val_acc: 0.3915\n",
            "Epoch 561/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3477 - val_loss: 1.8453 - val_acc: 0.3930\n",
            "Epoch 562/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8994 - acc: 0.3488 - val_loss: 1.8466 - val_acc: 0.3918\n",
            "Epoch 563/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3495 - val_loss: 1.8468 - val_acc: 0.3927\n",
            "Epoch 564/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3501 - val_loss: 1.8436 - val_acc: 0.3927\n",
            "Epoch 565/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3497 - val_loss: 1.8464 - val_acc: 0.3926\n",
            "Epoch 566/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3487 - val_loss: 1.8471 - val_acc: 0.3918\n",
            "Epoch 567/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3486 - val_loss: 1.8474 - val_acc: 0.3920\n",
            "Epoch 568/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3472 - val_loss: 1.8481 - val_acc: 0.3922\n",
            "Epoch 569/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3500 - val_loss: 1.8464 - val_acc: 0.3927\n",
            "Epoch 570/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3490 - val_loss: 1.8459 - val_acc: 0.3922\n",
            "Epoch 571/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3498 - val_loss: 1.8460 - val_acc: 0.3930\n",
            "Epoch 572/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8988 - acc: 0.3494 - val_loss: 1.8472 - val_acc: 0.3928\n",
            "Epoch 573/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3505 - val_loss: 1.8453 - val_acc: 0.3932\n",
            "Epoch 574/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3498 - val_loss: 1.8465 - val_acc: 0.3919\n",
            "Epoch 575/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9004 - acc: 0.3472 - val_loss: 1.8483 - val_acc: 0.3917\n",
            "Epoch 576/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8989 - acc: 0.3491 - val_loss: 1.8470 - val_acc: 0.3912\n",
            "Epoch 577/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3494 - val_loss: 1.8448 - val_acc: 0.3936\n",
            "Epoch 578/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3500 - val_loss: 1.8451 - val_acc: 0.3929\n",
            "Epoch 579/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3496 - val_loss: 1.8463 - val_acc: 0.3925\n",
            "Epoch 580/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3488 - val_loss: 1.8473 - val_acc: 0.3926\n",
            "Epoch 581/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3493 - val_loss: 1.8480 - val_acc: 0.3915\n",
            "Epoch 582/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3493 - val_loss: 1.8453 - val_acc: 0.3926\n",
            "Epoch 583/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3485 - val_loss: 1.8453 - val_acc: 0.3915\n",
            "Epoch 584/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3491 - val_loss: 1.8439 - val_acc: 0.3922\n",
            "Epoch 585/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3492 - val_loss: 1.8443 - val_acc: 0.3919\n",
            "Epoch 586/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8979 - acc: 0.3494 - val_loss: 1.8506 - val_acc: 0.3905\n",
            "Epoch 587/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3492 - val_loss: 1.8477 - val_acc: 0.3916\n",
            "Epoch 588/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3493 - val_loss: 1.8443 - val_acc: 0.3935\n",
            "Epoch 589/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8996 - acc: 0.3483 - val_loss: 1.8477 - val_acc: 0.3898\n",
            "Epoch 590/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3492 - val_loss: 1.8455 - val_acc: 0.3920\n",
            "Epoch 591/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3503 - val_loss: 1.8438 - val_acc: 0.3934\n",
            "Epoch 592/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3501 - val_loss: 1.8437 - val_acc: 0.3932\n",
            "Epoch 593/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9001 - acc: 0.3481 - val_loss: 1.8474 - val_acc: 0.3923\n",
            "Epoch 594/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3491 - val_loss: 1.8464 - val_acc: 0.3917\n",
            "Epoch 595/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3503 - val_loss: 1.8461 - val_acc: 0.3924\n",
            "Epoch 596/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3496 - val_loss: 1.8446 - val_acc: 0.3926\n",
            "Epoch 597/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3489 - val_loss: 1.8464 - val_acc: 0.3910\n",
            "Epoch 598/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3504 - val_loss: 1.8486 - val_acc: 0.3906\n",
            "Epoch 599/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3485 - val_loss: 1.8468 - val_acc: 0.3908\n",
            "Epoch 600/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3499 - val_loss: 1.8466 - val_acc: 0.3907\n",
            "Epoch 601/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3490 - val_loss: 1.8488 - val_acc: 0.3905\n",
            "Epoch 602/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3491 - val_loss: 1.8460 - val_acc: 0.3915\n",
            "Epoch 603/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3491 - val_loss: 1.8462 - val_acc: 0.3917\n",
            "Epoch 604/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8989 - acc: 0.3494 - val_loss: 1.8452 - val_acc: 0.3913\n",
            "Epoch 605/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8992 - acc: 0.3494 - val_loss: 1.8460 - val_acc: 0.3919\n",
            "Epoch 606/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3503 - val_loss: 1.8441 - val_acc: 0.3929\n",
            "Epoch 607/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3488 - val_loss: 1.8455 - val_acc: 0.3917\n",
            "Epoch 608/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3508 - val_loss: 1.8468 - val_acc: 0.3916\n",
            "Epoch 609/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3491 - val_loss: 1.8460 - val_acc: 0.3929\n",
            "Epoch 610/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3483 - val_loss: 1.8454 - val_acc: 0.3922\n",
            "Epoch 611/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3498 - val_loss: 1.8465 - val_acc: 0.3901\n",
            "Epoch 612/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8988 - acc: 0.3486 - val_loss: 1.8457 - val_acc: 0.3915\n",
            "Epoch 613/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.8975 - acc: 0.3495 - val_loss: 1.8477 - val_acc: 0.3911\n",
            "Epoch 614/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3515 - val_loss: 1.8440 - val_acc: 0.3929\n",
            "Epoch 615/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3482 - val_loss: 1.8488 - val_acc: 0.3904\n",
            "Epoch 616/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8999 - acc: 0.3496 - val_loss: 1.8462 - val_acc: 0.3920\n",
            "Epoch 617/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3484 - val_loss: 1.8462 - val_acc: 0.3920\n",
            "Epoch 618/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3501 - val_loss: 1.8460 - val_acc: 0.3912\n",
            "Epoch 619/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3507 - val_loss: 1.8454 - val_acc: 0.3916\n",
            "Epoch 620/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3490 - val_loss: 1.8453 - val_acc: 0.3916\n",
            "Epoch 621/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3509 - val_loss: 1.8473 - val_acc: 0.3915\n",
            "Epoch 622/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8988 - acc: 0.3480 - val_loss: 1.8451 - val_acc: 0.3915\n",
            "Epoch 623/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3493 - val_loss: 1.8474 - val_acc: 0.3911\n",
            "Epoch 624/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8979 - acc: 0.3502 - val_loss: 1.8481 - val_acc: 0.3919\n",
            "Epoch 625/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3497 - val_loss: 1.8457 - val_acc: 0.3932\n",
            "Epoch 626/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8984 - acc: 0.3490 - val_loss: 1.8474 - val_acc: 0.3918\n",
            "Epoch 627/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3488 - val_loss: 1.8475 - val_acc: 0.3914\n",
            "Epoch 628/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3500 - val_loss: 1.8439 - val_acc: 0.3936\n",
            "Epoch 629/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3494 - val_loss: 1.8477 - val_acc: 0.3906\n",
            "Epoch 630/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3492 - val_loss: 1.8466 - val_acc: 0.3912\n",
            "Epoch 631/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3504 - val_loss: 1.8466 - val_acc: 0.3907\n",
            "Epoch 632/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3497 - val_loss: 1.8488 - val_acc: 0.3911\n",
            "Epoch 633/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.8990 - acc: 0.3495 - val_loss: 1.8497 - val_acc: 0.3900\n",
            "Epoch 634/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8991 - acc: 0.3488 - val_loss: 1.8469 - val_acc: 0.3898\n",
            "Epoch 635/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3504 - val_loss: 1.8469 - val_acc: 0.3903\n",
            "Epoch 636/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3488 - val_loss: 1.8478 - val_acc: 0.3909\n",
            "Epoch 637/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3509 - val_loss: 1.8462 - val_acc: 0.3918\n",
            "Epoch 638/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3498 - val_loss: 1.8454 - val_acc: 0.3906\n",
            "Epoch 639/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3486 - val_loss: 1.8472 - val_acc: 0.3917\n",
            "Epoch 640/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3496 - val_loss: 1.8447 - val_acc: 0.3933\n",
            "Epoch 641/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3503 - val_loss: 1.8453 - val_acc: 0.3923\n",
            "Epoch 642/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3488 - val_loss: 1.8464 - val_acc: 0.3931\n",
            "Epoch 643/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3495 - val_loss: 1.8464 - val_acc: 0.3911\n",
            "Epoch 644/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3497 - val_loss: 1.8470 - val_acc: 0.3914\n",
            "Epoch 645/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3492 - val_loss: 1.8464 - val_acc: 0.3919\n",
            "Epoch 646/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3495 - val_loss: 1.8463 - val_acc: 0.3926\n",
            "Epoch 647/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3491 - val_loss: 1.8458 - val_acc: 0.3925\n",
            "Epoch 648/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8985 - acc: 0.3483 - val_loss: 1.8461 - val_acc: 0.3920\n",
            "Epoch 649/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3487 - val_loss: 1.8470 - val_acc: 0.3923\n",
            "Epoch 650/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8984 - acc: 0.3487 - val_loss: 1.8454 - val_acc: 0.3925\n",
            "Epoch 651/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3498 - val_loss: 1.8442 - val_acc: 0.3919\n",
            "Epoch 652/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3495 - val_loss: 1.8455 - val_acc: 0.3922\n",
            "Epoch 653/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8940 - acc: 0.3496 - val_loss: 1.8458 - val_acc: 0.3941\n",
            "Epoch 654/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3494 - val_loss: 1.8475 - val_acc: 0.3921\n",
            "Epoch 655/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3488 - val_loss: 1.8462 - val_acc: 0.3929\n",
            "Epoch 656/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3499 - val_loss: 1.8459 - val_acc: 0.3908\n",
            "Epoch 657/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8979 - acc: 0.3502 - val_loss: 1.8478 - val_acc: 0.3902\n",
            "Epoch 658/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3487 - val_loss: 1.8461 - val_acc: 0.3927\n",
            "Epoch 659/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.9009 - acc: 0.3487 - val_loss: 1.8482 - val_acc: 0.3917\n",
            "Epoch 660/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3484 - val_loss: 1.8441 - val_acc: 0.3928\n",
            "Epoch 661/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3498 - val_loss: 1.8431 - val_acc: 0.3928\n",
            "Epoch 662/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3479 - val_loss: 1.8461 - val_acc: 0.3923\n",
            "Epoch 663/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8979 - acc: 0.3490 - val_loss: 1.8459 - val_acc: 0.3918\n",
            "Epoch 664/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8986 - acc: 0.3488 - val_loss: 1.8468 - val_acc: 0.3929\n",
            "Epoch 665/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3488 - val_loss: 1.8434 - val_acc: 0.3934\n",
            "Epoch 666/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3494 - val_loss: 1.8464 - val_acc: 0.3932\n",
            "Epoch 667/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3493 - val_loss: 1.8464 - val_acc: 0.3919\n",
            "Epoch 668/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3500 - val_loss: 1.8453 - val_acc: 0.3927\n",
            "Epoch 669/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3481 - val_loss: 1.8483 - val_acc: 0.3906\n",
            "Epoch 670/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3490 - val_loss: 1.8442 - val_acc: 0.3936\n",
            "Epoch 671/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8979 - acc: 0.3481 - val_loss: 1.8470 - val_acc: 0.3928\n",
            "Epoch 672/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8988 - acc: 0.3495 - val_loss: 1.8482 - val_acc: 0.3916\n",
            "Epoch 673/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3500 - val_loss: 1.8471 - val_acc: 0.3917\n",
            "Epoch 674/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3491 - val_loss: 1.8452 - val_acc: 0.3917\n",
            "Epoch 675/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3498 - val_loss: 1.8456 - val_acc: 0.3930\n",
            "Epoch 676/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3496 - val_loss: 1.8461 - val_acc: 0.3926\n",
            "Epoch 677/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3500 - val_loss: 1.8459 - val_acc: 0.3931\n",
            "Epoch 678/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3496 - val_loss: 1.8462 - val_acc: 0.3930\n",
            "Epoch 679/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8979 - acc: 0.3493 - val_loss: 1.8467 - val_acc: 0.3926\n",
            "Epoch 680/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3502 - val_loss: 1.8466 - val_acc: 0.3930\n",
            "Epoch 681/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3500 - val_loss: 1.8490 - val_acc: 0.3918\n",
            "Epoch 682/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3498 - val_loss: 1.8465 - val_acc: 0.3920\n",
            "Epoch 683/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3493 - val_loss: 1.8458 - val_acc: 0.3925\n",
            "Epoch 684/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3492 - val_loss: 1.8481 - val_acc: 0.3915\n",
            "Epoch 685/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8991 - acc: 0.3484 - val_loss: 1.8456 - val_acc: 0.3925\n",
            "Epoch 686/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3493 - val_loss: 1.8452 - val_acc: 0.3923\n",
            "Epoch 687/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3492 - val_loss: 1.8457 - val_acc: 0.3918\n",
            "Epoch 688/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3495 - val_loss: 1.8468 - val_acc: 0.3924\n",
            "Epoch 689/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3499 - val_loss: 1.8458 - val_acc: 0.3920\n",
            "Epoch 690/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3502 - val_loss: 1.8426 - val_acc: 0.3928\n",
            "Epoch 691/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3492 - val_loss: 1.8448 - val_acc: 0.3921\n",
            "Epoch 692/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8942 - acc: 0.3512 - val_loss: 1.8473 - val_acc: 0.3912\n",
            "Epoch 693/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3490 - val_loss: 1.8461 - val_acc: 0.3929\n",
            "Epoch 694/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3499 - val_loss: 1.8456 - val_acc: 0.3924\n",
            "Epoch 695/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3494 - val_loss: 1.8479 - val_acc: 0.3914\n",
            "Epoch 696/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3506 - val_loss: 1.8470 - val_acc: 0.3913\n",
            "Epoch 697/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3489 - val_loss: 1.8484 - val_acc: 0.3908\n",
            "Epoch 698/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3492 - val_loss: 1.8474 - val_acc: 0.3910\n",
            "Epoch 699/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3492 - val_loss: 1.8462 - val_acc: 0.3901\n",
            "Epoch 700/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3505 - val_loss: 1.8458 - val_acc: 0.3925\n",
            "Epoch 701/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3493 - val_loss: 1.8448 - val_acc: 0.3914\n",
            "Epoch 702/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3503 - val_loss: 1.8443 - val_acc: 0.3916\n",
            "Epoch 703/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3488 - val_loss: 1.8458 - val_acc: 0.3922\n",
            "Epoch 704/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3499 - val_loss: 1.8474 - val_acc: 0.3913\n",
            "Epoch 705/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3494 - val_loss: 1.8479 - val_acc: 0.3915\n",
            "Epoch 706/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3509 - val_loss: 1.8489 - val_acc: 0.3913\n",
            "Epoch 707/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3495 - val_loss: 1.8481 - val_acc: 0.3915\n",
            "Epoch 708/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3495 - val_loss: 1.8497 - val_acc: 0.3915\n",
            "Epoch 709/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3484 - val_loss: 1.8450 - val_acc: 0.3913\n",
            "Epoch 710/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3497 - val_loss: 1.8452 - val_acc: 0.3927\n",
            "Epoch 711/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3491 - val_loss: 1.8480 - val_acc: 0.3913\n",
            "Epoch 712/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3496 - val_loss: 1.8462 - val_acc: 0.3920\n",
            "Epoch 713/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3492 - val_loss: 1.8455 - val_acc: 0.3919\n",
            "Epoch 714/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3496 - val_loss: 1.8474 - val_acc: 0.3915\n",
            "Epoch 715/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3490 - val_loss: 1.8455 - val_acc: 0.3924\n",
            "Epoch 716/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3495 - val_loss: 1.8450 - val_acc: 0.3921\n",
            "Epoch 717/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3493 - val_loss: 1.8464 - val_acc: 0.3925\n",
            "Epoch 718/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3488 - val_loss: 1.8470 - val_acc: 0.3917\n",
            "Epoch 719/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3497 - val_loss: 1.8469 - val_acc: 0.3927\n",
            "Epoch 720/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3499 - val_loss: 1.8478 - val_acc: 0.3911\n",
            "Epoch 721/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3491 - val_loss: 1.8498 - val_acc: 0.3911\n",
            "Epoch 722/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3490 - val_loss: 1.8482 - val_acc: 0.3919\n",
            "Epoch 723/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3492 - val_loss: 1.8433 - val_acc: 0.3926\n",
            "Epoch 724/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3495 - val_loss: 1.8448 - val_acc: 0.3926\n",
            "Epoch 725/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3481 - val_loss: 1.8457 - val_acc: 0.3911\n",
            "Epoch 726/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3482 - val_loss: 1.8446 - val_acc: 0.3925\n",
            "Epoch 727/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3485 - val_loss: 1.8456 - val_acc: 0.3936\n",
            "Epoch 728/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3501 - val_loss: 1.8453 - val_acc: 0.3920\n",
            "Epoch 729/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3479 - val_loss: 1.8463 - val_acc: 0.3920\n",
            "Epoch 730/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8944 - acc: 0.3502 - val_loss: 1.8438 - val_acc: 0.3917\n",
            "Epoch 731/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3505 - val_loss: 1.8458 - val_acc: 0.3925\n",
            "Epoch 732/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3508 - val_loss: 1.8476 - val_acc: 0.3917\n",
            "Epoch 733/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3484 - val_loss: 1.8451 - val_acc: 0.3922\n",
            "Epoch 734/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3500 - val_loss: 1.8446 - val_acc: 0.3936\n",
            "Epoch 735/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3494 - val_loss: 1.8448 - val_acc: 0.3929\n",
            "Epoch 736/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3494 - val_loss: 1.8462 - val_acc: 0.3925\n",
            "Epoch 737/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3497 - val_loss: 1.8444 - val_acc: 0.3933\n",
            "Epoch 738/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.8975 - acc: 0.3491 - val_loss: 1.8432 - val_acc: 0.3941\n",
            "Epoch 739/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.8966 - acc: 0.3494 - val_loss: 1.8463 - val_acc: 0.3919\n",
            "Epoch 740/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3501 - val_loss: 1.8450 - val_acc: 0.3927\n",
            "Epoch 741/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3501 - val_loss: 1.8438 - val_acc: 0.3933\n",
            "Epoch 742/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3507 - val_loss: 1.8453 - val_acc: 0.3928\n",
            "Epoch 743/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8946 - acc: 0.3488 - val_loss: 1.8449 - val_acc: 0.3924\n",
            "Epoch 744/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3504 - val_loss: 1.8450 - val_acc: 0.3930\n",
            "Epoch 745/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3493 - val_loss: 1.8452 - val_acc: 0.3925\n",
            "Epoch 746/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3506 - val_loss: 1.8467 - val_acc: 0.3923\n",
            "Epoch 747/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3487 - val_loss: 1.8464 - val_acc: 0.3917\n",
            "Epoch 748/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3492 - val_loss: 1.8480 - val_acc: 0.3915\n",
            "Epoch 749/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3496 - val_loss: 1.8472 - val_acc: 0.3920\n",
            "Epoch 750/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3492 - val_loss: 1.8440 - val_acc: 0.3920\n",
            "Epoch 751/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3484 - val_loss: 1.8461 - val_acc: 0.3915\n",
            "Epoch 752/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3493 - val_loss: 1.8440 - val_acc: 0.3937\n",
            "Epoch 753/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3496 - val_loss: 1.8476 - val_acc: 0.3905\n",
            "Epoch 754/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3483 - val_loss: 1.8462 - val_acc: 0.3910\n",
            "Epoch 755/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3500 - val_loss: 1.8445 - val_acc: 0.3925\n",
            "Epoch 756/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3500 - val_loss: 1.8483 - val_acc: 0.3911\n",
            "Epoch 757/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3498 - val_loss: 1.8444 - val_acc: 0.3924\n",
            "Epoch 758/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3492 - val_loss: 1.8472 - val_acc: 0.3918\n",
            "Epoch 759/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3491 - val_loss: 1.8480 - val_acc: 0.3912\n",
            "Epoch 760/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3488 - val_loss: 1.8491 - val_acc: 0.3909\n",
            "Epoch 761/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3497 - val_loss: 1.8454 - val_acc: 0.3920\n",
            "Epoch 762/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3499 - val_loss: 1.8472 - val_acc: 0.3911\n",
            "Epoch 763/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3499 - val_loss: 1.8453 - val_acc: 0.3923\n",
            "Epoch 764/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3494 - val_loss: 1.8449 - val_acc: 0.3928\n",
            "Epoch 765/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3490 - val_loss: 1.8457 - val_acc: 0.3921\n",
            "Epoch 766/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8943 - acc: 0.3498 - val_loss: 1.8448 - val_acc: 0.3924\n",
            "Epoch 767/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3503 - val_loss: 1.8451 - val_acc: 0.3924\n",
            "Epoch 768/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3493 - val_loss: 1.8445 - val_acc: 0.3922\n",
            "Epoch 769/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3495 - val_loss: 1.8442 - val_acc: 0.3922\n",
            "Epoch 770/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8973 - acc: 0.3478 - val_loss: 1.8462 - val_acc: 0.3909\n",
            "Epoch 771/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3489 - val_loss: 1.8463 - val_acc: 0.3933\n",
            "Epoch 772/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3489 - val_loss: 1.8467 - val_acc: 0.3921\n",
            "Epoch 773/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8947 - acc: 0.3494 - val_loss: 1.8469 - val_acc: 0.3921\n",
            "Epoch 774/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3495 - val_loss: 1.8454 - val_acc: 0.3924\n",
            "Epoch 775/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3495 - val_loss: 1.8420 - val_acc: 0.3933\n",
            "Epoch 776/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3500 - val_loss: 1.8461 - val_acc: 0.3914\n",
            "Epoch 777/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3486 - val_loss: 1.8481 - val_acc: 0.3908\n",
            "Epoch 778/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3505 - val_loss: 1.8455 - val_acc: 0.3912\n",
            "Epoch 779/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8945 - acc: 0.3495 - val_loss: 1.8460 - val_acc: 0.3920\n",
            "Epoch 780/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8948 - acc: 0.3504 - val_loss: 1.8484 - val_acc: 0.3917\n",
            "Epoch 781/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3488 - val_loss: 1.8454 - val_acc: 0.3926\n",
            "Epoch 782/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3494 - val_loss: 1.8472 - val_acc: 0.3915\n",
            "Epoch 783/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8948 - acc: 0.3503 - val_loss: 1.8465 - val_acc: 0.3913\n",
            "Epoch 784/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3495 - val_loss: 1.8454 - val_acc: 0.3918\n",
            "Epoch 785/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3503 - val_loss: 1.8456 - val_acc: 0.3926\n",
            "Epoch 786/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3493 - val_loss: 1.8476 - val_acc: 0.3915\n",
            "Epoch 787/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3502 - val_loss: 1.8466 - val_acc: 0.3917\n",
            "Epoch 788/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3498 - val_loss: 1.8510 - val_acc: 0.3904\n",
            "Epoch 789/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3522 - val_loss: 1.8463 - val_acc: 0.3930\n",
            "Epoch 790/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3501 - val_loss: 1.8439 - val_acc: 0.3925\n",
            "Epoch 791/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8932 - acc: 0.3513 - val_loss: 1.8444 - val_acc: 0.3919\n",
            "Epoch 792/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3490 - val_loss: 1.8458 - val_acc: 0.3923\n",
            "Epoch 793/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3503 - val_loss: 1.8456 - val_acc: 0.3917\n",
            "Epoch 794/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8945 - acc: 0.3504 - val_loss: 1.8435 - val_acc: 0.3932\n",
            "Epoch 795/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3485 - val_loss: 1.8476 - val_acc: 0.3919\n",
            "Epoch 796/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8988 - acc: 0.3491 - val_loss: 1.8475 - val_acc: 0.3915\n",
            "Epoch 797/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8990 - acc: 0.3484 - val_loss: 1.8468 - val_acc: 0.3920\n",
            "Epoch 798/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3500 - val_loss: 1.8466 - val_acc: 0.3929\n",
            "Epoch 799/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3488 - val_loss: 1.8477 - val_acc: 0.3925\n",
            "Epoch 800/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3492 - val_loss: 1.8454 - val_acc: 0.3912\n",
            "Epoch 801/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3500 - val_loss: 1.8483 - val_acc: 0.3916\n",
            "Epoch 802/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8977 - acc: 0.3500 - val_loss: 1.8457 - val_acc: 0.3906\n",
            "Epoch 803/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3513 - val_loss: 1.8455 - val_acc: 0.3905\n",
            "Epoch 804/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3500 - val_loss: 1.8466 - val_acc: 0.3911\n",
            "Epoch 805/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3499 - val_loss: 1.8454 - val_acc: 0.3921\n",
            "Epoch 806/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3505 - val_loss: 1.8441 - val_acc: 0.3912\n",
            "Epoch 807/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3494 - val_loss: 1.8457 - val_acc: 0.3917\n",
            "Epoch 808/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3500 - val_loss: 1.8457 - val_acc: 0.3905\n",
            "Epoch 809/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3493 - val_loss: 1.8434 - val_acc: 0.3932\n",
            "Epoch 810/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3498 - val_loss: 1.8454 - val_acc: 0.3909\n",
            "Epoch 811/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3485 - val_loss: 1.8436 - val_acc: 0.3912\n",
            "Epoch 812/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3502 - val_loss: 1.8461 - val_acc: 0.3916\n",
            "Epoch 813/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3477 - val_loss: 1.8474 - val_acc: 0.3916\n",
            "Epoch 814/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3482 - val_loss: 1.8499 - val_acc: 0.3909\n",
            "Epoch 815/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3500 - val_loss: 1.8470 - val_acc: 0.3910\n",
            "Epoch 816/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3497 - val_loss: 1.8495 - val_acc: 0.3912\n",
            "Epoch 817/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3501 - val_loss: 1.8467 - val_acc: 0.3917\n",
            "Epoch 818/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3494 - val_loss: 1.8450 - val_acc: 0.3921\n",
            "Epoch 819/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3491 - val_loss: 1.8488 - val_acc: 0.3907\n",
            "Epoch 820/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3497 - val_loss: 1.8467 - val_acc: 0.3914\n",
            "Epoch 821/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3500 - val_loss: 1.8459 - val_acc: 0.3924\n",
            "Epoch 822/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8984 - acc: 0.3485 - val_loss: 1.8477 - val_acc: 0.3907\n",
            "Epoch 823/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8981 - acc: 0.3500 - val_loss: 1.8471 - val_acc: 0.3910\n",
            "Epoch 824/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3490 - val_loss: 1.8494 - val_acc: 0.3922\n",
            "Epoch 825/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3491 - val_loss: 1.8473 - val_acc: 0.3919\n",
            "Epoch 826/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3492 - val_loss: 1.8473 - val_acc: 0.3916\n",
            "Epoch 827/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8975 - acc: 0.3499 - val_loss: 1.8477 - val_acc: 0.3916\n",
            "Epoch 828/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3499 - val_loss: 1.8457 - val_acc: 0.3928\n",
            "Epoch 829/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3498 - val_loss: 1.8463 - val_acc: 0.3911\n",
            "Epoch 830/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8983 - acc: 0.3491 - val_loss: 1.8464 - val_acc: 0.3921\n",
            "Epoch 831/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3488 - val_loss: 1.8481 - val_acc: 0.3911\n",
            "Epoch 832/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3498 - val_loss: 1.8461 - val_acc: 0.3923\n",
            "Epoch 833/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3494 - val_loss: 1.8474 - val_acc: 0.3913\n",
            "Epoch 834/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8980 - acc: 0.3493 - val_loss: 1.8469 - val_acc: 0.3920\n",
            "Epoch 835/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3494 - val_loss: 1.8445 - val_acc: 0.3927\n",
            "Epoch 836/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3506 - val_loss: 1.8428 - val_acc: 0.3929\n",
            "Epoch 837/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3486 - val_loss: 1.8467 - val_acc: 0.3917\n",
            "Epoch 838/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3511 - val_loss: 1.8436 - val_acc: 0.3916\n",
            "Epoch 839/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3486 - val_loss: 1.8482 - val_acc: 0.3914\n",
            "Epoch 840/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3476 - val_loss: 1.8483 - val_acc: 0.3913\n",
            "Epoch 841/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3486 - val_loss: 1.8456 - val_acc: 0.3922\n",
            "Epoch 842/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8941 - acc: 0.3507 - val_loss: 1.8460 - val_acc: 0.3922\n",
            "Epoch 843/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3491 - val_loss: 1.8475 - val_acc: 0.3920\n",
            "Epoch 844/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8943 - acc: 0.3503 - val_loss: 1.8468 - val_acc: 0.3904\n",
            "Epoch 845/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3494 - val_loss: 1.8458 - val_acc: 0.3905\n",
            "Epoch 846/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3496 - val_loss: 1.8438 - val_acc: 0.3917\n",
            "Epoch 847/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3494 - val_loss: 1.8490 - val_acc: 0.3898\n",
            "Epoch 848/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3499 - val_loss: 1.8461 - val_acc: 0.3908\n",
            "Epoch 849/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3500 - val_loss: 1.8477 - val_acc: 0.3914\n",
            "Epoch 850/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3498 - val_loss: 1.8440 - val_acc: 0.3911\n",
            "Epoch 851/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3501 - val_loss: 1.8455 - val_acc: 0.3918\n",
            "Epoch 852/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3507 - val_loss: 1.8450 - val_acc: 0.3920\n",
            "Epoch 853/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3495 - val_loss: 1.8476 - val_acc: 0.3923\n",
            "Epoch 854/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8978 - acc: 0.3490 - val_loss: 1.8462 - val_acc: 0.3918\n",
            "Epoch 855/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3500 - val_loss: 1.8448 - val_acc: 0.3918\n",
            "Epoch 856/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3500 - val_loss: 1.8470 - val_acc: 0.3919\n",
            "Epoch 857/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3493 - val_loss: 1.8481 - val_acc: 0.3913\n",
            "Epoch 858/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3495 - val_loss: 1.8485 - val_acc: 0.3901\n",
            "Epoch 859/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8937 - acc: 0.3499 - val_loss: 1.8483 - val_acc: 0.3901\n",
            "Epoch 860/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3488 - val_loss: 1.8469 - val_acc: 0.3915\n",
            "Epoch 861/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3502 - val_loss: 1.8491 - val_acc: 0.3901\n",
            "Epoch 862/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3490 - val_loss: 1.8467 - val_acc: 0.3924\n",
            "Epoch 863/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3493 - val_loss: 1.8464 - val_acc: 0.3919\n",
            "Epoch 864/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3484 - val_loss: 1.8464 - val_acc: 0.3915\n",
            "Epoch 865/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3498 - val_loss: 1.8502 - val_acc: 0.3909\n",
            "Epoch 866/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3495 - val_loss: 1.8482 - val_acc: 0.3924\n",
            "Epoch 867/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8944 - acc: 0.3516 - val_loss: 1.8443 - val_acc: 0.3919\n",
            "Epoch 868/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3500 - val_loss: 1.8471 - val_acc: 0.3912\n",
            "Epoch 869/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8941 - acc: 0.3507 - val_loss: 1.8452 - val_acc: 0.3915\n",
            "Epoch 870/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3510 - val_loss: 1.8490 - val_acc: 0.3913\n",
            "Epoch 871/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3505 - val_loss: 1.8471 - val_acc: 0.3900\n",
            "Epoch 872/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3512 - val_loss: 1.8446 - val_acc: 0.3904\n",
            "Epoch 873/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3494 - val_loss: 1.8484 - val_acc: 0.3906\n",
            "Epoch 874/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3498 - val_loss: 1.8471 - val_acc: 0.3911\n",
            "Epoch 875/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3514 - val_loss: 1.8473 - val_acc: 0.3906\n",
            "Epoch 876/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8982 - acc: 0.3488 - val_loss: 1.8472 - val_acc: 0.3918\n",
            "Epoch 877/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3497 - val_loss: 1.8476 - val_acc: 0.3913\n",
            "Epoch 878/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8934 - acc: 0.3504 - val_loss: 1.8474 - val_acc: 0.3916\n",
            "Epoch 879/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3491 - val_loss: 1.8432 - val_acc: 0.3905\n",
            "Epoch 880/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3504 - val_loss: 1.8470 - val_acc: 0.3909\n",
            "Epoch 881/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3485 - val_loss: 1.8472 - val_acc: 0.3900\n",
            "Epoch 882/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3488 - val_loss: 1.8487 - val_acc: 0.3895\n",
            "Epoch 883/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3495 - val_loss: 1.8434 - val_acc: 0.3910\n",
            "Epoch 884/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8939 - acc: 0.3507 - val_loss: 1.8452 - val_acc: 0.3905\n",
            "Epoch 885/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3498 - val_loss: 1.8470 - val_acc: 0.3906\n",
            "Epoch 886/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3491 - val_loss: 1.8460 - val_acc: 0.3906\n",
            "Epoch 887/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3501 - val_loss: 1.8470 - val_acc: 0.3906\n",
            "Epoch 888/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3506 - val_loss: 1.8450 - val_acc: 0.3917\n",
            "Epoch 889/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8971 - acc: 0.3491 - val_loss: 1.8451 - val_acc: 0.3912\n",
            "Epoch 890/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3477 - val_loss: 1.8458 - val_acc: 0.3909\n",
            "Epoch 891/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3503 - val_loss: 1.8448 - val_acc: 0.3912\n",
            "Epoch 892/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3507 - val_loss: 1.8418 - val_acc: 0.3936\n",
            "Epoch 893/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8948 - acc: 0.3502 - val_loss: 1.8469 - val_acc: 0.3906\n",
            "Epoch 894/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3502 - val_loss: 1.8434 - val_acc: 0.3917\n",
            "Epoch 895/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3497 - val_loss: 1.8468 - val_acc: 0.3909\n",
            "Epoch 896/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3493 - val_loss: 1.8427 - val_acc: 0.3927\n",
            "Epoch 897/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3501 - val_loss: 1.8465 - val_acc: 0.3921\n",
            "Epoch 898/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3483 - val_loss: 1.8513 - val_acc: 0.3908\n",
            "Epoch 899/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3506 - val_loss: 1.8481 - val_acc: 0.3909\n",
            "Epoch 900/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8946 - acc: 0.3493 - val_loss: 1.8447 - val_acc: 0.3915\n",
            "Epoch 901/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3500 - val_loss: 1.8446 - val_acc: 0.3912\n",
            "Epoch 902/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3495 - val_loss: 1.8480 - val_acc: 0.3910\n",
            "Epoch 903/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3505 - val_loss: 1.8455 - val_acc: 0.3913\n",
            "Epoch 904/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8940 - acc: 0.3492 - val_loss: 1.8444 - val_acc: 0.3925\n",
            "Epoch 905/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8970 - acc: 0.3472 - val_loss: 1.8445 - val_acc: 0.3914\n",
            "Epoch 906/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8945 - acc: 0.3495 - val_loss: 1.8448 - val_acc: 0.3914\n",
            "Epoch 907/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8974 - acc: 0.3495 - val_loss: 1.8463 - val_acc: 0.3910\n",
            "Epoch 908/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8957 - acc: 0.3494 - val_loss: 1.8435 - val_acc: 0.3926\n",
            "Epoch 909/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8947 - acc: 0.3493 - val_loss: 1.8470 - val_acc: 0.3917\n",
            "Epoch 910/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3495 - val_loss: 1.8484 - val_acc: 0.3908\n",
            "Epoch 911/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3503 - val_loss: 1.8474 - val_acc: 0.3913\n",
            "Epoch 912/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3493 - val_loss: 1.8456 - val_acc: 0.3914\n",
            "Epoch 913/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3486 - val_loss: 1.8464 - val_acc: 0.3905\n",
            "Epoch 914/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8945 - acc: 0.3499 - val_loss: 1.8467 - val_acc: 0.3916\n",
            "Epoch 915/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3494 - val_loss: 1.8479 - val_acc: 0.3916\n",
            "Epoch 916/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3512 - val_loss: 1.8480 - val_acc: 0.3899\n",
            "Epoch 917/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3493 - val_loss: 1.8461 - val_acc: 0.3915\n",
            "Epoch 918/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3505 - val_loss: 1.8448 - val_acc: 0.3917\n",
            "Epoch 919/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8946 - acc: 0.3510 - val_loss: 1.8454 - val_acc: 0.3922\n",
            "Epoch 920/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3494 - val_loss: 1.8477 - val_acc: 0.3900\n",
            "Epoch 921/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3485 - val_loss: 1.8475 - val_acc: 0.3910\n",
            "Epoch 922/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8968 - acc: 0.3500 - val_loss: 1.8460 - val_acc: 0.3913\n",
            "Epoch 923/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8947 - acc: 0.3503 - val_loss: 1.8456 - val_acc: 0.3916\n",
            "Epoch 924/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3481 - val_loss: 1.8474 - val_acc: 0.3909\n",
            "Epoch 925/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3492 - val_loss: 1.8447 - val_acc: 0.3924\n",
            "Epoch 926/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3490 - val_loss: 1.8470 - val_acc: 0.3907\n",
            "Epoch 927/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3491 - val_loss: 1.8467 - val_acc: 0.3917\n",
            "Epoch 928/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8947 - acc: 0.3516 - val_loss: 1.8457 - val_acc: 0.3912\n",
            "Epoch 929/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3497 - val_loss: 1.8453 - val_acc: 0.3914\n",
            "Epoch 930/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8943 - acc: 0.3490 - val_loss: 1.8440 - val_acc: 0.3927\n",
            "Epoch 931/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3492 - val_loss: 1.8471 - val_acc: 0.3916\n",
            "Epoch 932/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3488 - val_loss: 1.8437 - val_acc: 0.3921\n",
            "Epoch 933/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8941 - acc: 0.3497 - val_loss: 1.8454 - val_acc: 0.3924\n",
            "Epoch 934/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3494 - val_loss: 1.8432 - val_acc: 0.3925\n",
            "Epoch 935/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3502 - val_loss: 1.8460 - val_acc: 0.3903\n",
            "Epoch 936/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8927 - acc: 0.3509 - val_loss: 1.8471 - val_acc: 0.3907\n",
            "Epoch 937/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3494 - val_loss: 1.8455 - val_acc: 0.3920\n",
            "Epoch 938/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3504 - val_loss: 1.8474 - val_acc: 0.3911\n",
            "Epoch 939/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8938 - acc: 0.3522 - val_loss: 1.8465 - val_acc: 0.3912\n",
            "Epoch 940/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3497 - val_loss: 1.8444 - val_acc: 0.3922\n",
            "Epoch 941/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3489 - val_loss: 1.8455 - val_acc: 0.3902\n",
            "Epoch 942/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3498 - val_loss: 1.8490 - val_acc: 0.3918\n",
            "Epoch 943/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3503 - val_loss: 1.8484 - val_acc: 0.3907\n",
            "Epoch 944/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8940 - acc: 0.3506 - val_loss: 1.8453 - val_acc: 0.3910\n",
            "Epoch 945/1000\n",
            "131559/131559 [==============================] - 0s 3us/sample - loss: 1.8956 - acc: 0.3501 - val_loss: 1.8445 - val_acc: 0.3913\n",
            "Epoch 946/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8976 - acc: 0.3479 - val_loss: 1.8476 - val_acc: 0.3907\n",
            "Epoch 947/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3508 - val_loss: 1.8446 - val_acc: 0.3925\n",
            "Epoch 948/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8972 - acc: 0.3490 - val_loss: 1.8472 - val_acc: 0.3918\n",
            "Epoch 949/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3490 - val_loss: 1.8456 - val_acc: 0.3915\n",
            "Epoch 950/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3482 - val_loss: 1.8467 - val_acc: 0.3913\n",
            "Epoch 951/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3496 - val_loss: 1.8450 - val_acc: 0.3912\n",
            "Epoch 952/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8946 - acc: 0.3500 - val_loss: 1.8473 - val_acc: 0.3914\n",
            "Epoch 953/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8967 - acc: 0.3481 - val_loss: 1.8502 - val_acc: 0.3892\n",
            "Epoch 954/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3505 - val_loss: 1.8453 - val_acc: 0.3915\n",
            "Epoch 955/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3491 - val_loss: 1.8482 - val_acc: 0.3905\n",
            "Epoch 956/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3505 - val_loss: 1.8484 - val_acc: 0.3909\n",
            "Epoch 957/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3493 - val_loss: 1.8477 - val_acc: 0.3901\n",
            "Epoch 958/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3495 - val_loss: 1.8464 - val_acc: 0.3918\n",
            "Epoch 959/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3501 - val_loss: 1.8425 - val_acc: 0.3936\n",
            "Epoch 960/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8966 - acc: 0.3504 - val_loss: 1.8488 - val_acc: 0.3899\n",
            "Epoch 961/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8941 - acc: 0.3500 - val_loss: 1.8452 - val_acc: 0.3908\n",
            "Epoch 962/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3506 - val_loss: 1.8484 - val_acc: 0.3901\n",
            "Epoch 963/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3490 - val_loss: 1.8483 - val_acc: 0.3899\n",
            "Epoch 964/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3502 - val_loss: 1.8453 - val_acc: 0.3918\n",
            "Epoch 965/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8951 - acc: 0.3494 - val_loss: 1.8463 - val_acc: 0.3907\n",
            "Epoch 966/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3490 - val_loss: 1.8452 - val_acc: 0.3913\n",
            "Epoch 967/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3488 - val_loss: 1.8491 - val_acc: 0.3899\n",
            "Epoch 968/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8938 - acc: 0.3500 - val_loss: 1.8474 - val_acc: 0.3896\n",
            "Epoch 969/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8929 - acc: 0.3506 - val_loss: 1.8460 - val_acc: 0.3896\n",
            "Epoch 970/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3482 - val_loss: 1.8469 - val_acc: 0.3903\n",
            "Epoch 971/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3491 - val_loss: 1.8464 - val_acc: 0.3910\n",
            "Epoch 972/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3503 - val_loss: 1.8465 - val_acc: 0.3910\n",
            "Epoch 973/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8930 - acc: 0.3504 - val_loss: 1.8450 - val_acc: 0.3905\n",
            "Epoch 974/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8954 - acc: 0.3507 - val_loss: 1.8475 - val_acc: 0.3910\n",
            "Epoch 975/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8965 - acc: 0.3494 - val_loss: 1.8472 - val_acc: 0.3919\n",
            "Epoch 976/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8963 - acc: 0.3497 - val_loss: 1.8438 - val_acc: 0.3920\n",
            "Epoch 977/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8958 - acc: 0.3499 - val_loss: 1.8471 - val_acc: 0.3924\n",
            "Epoch 978/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8955 - acc: 0.3490 - val_loss: 1.8474 - val_acc: 0.3902\n",
            "Epoch 979/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8939 - acc: 0.3494 - val_loss: 1.8447 - val_acc: 0.3915\n",
            "Epoch 980/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3489 - val_loss: 1.8484 - val_acc: 0.3913\n",
            "Epoch 981/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8956 - acc: 0.3507 - val_loss: 1.8476 - val_acc: 0.3907\n",
            "Epoch 982/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3496 - val_loss: 1.8447 - val_acc: 0.3915\n",
            "Epoch 983/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8961 - acc: 0.3504 - val_loss: 1.8483 - val_acc: 0.3910\n",
            "Epoch 984/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8939 - acc: 0.3492 - val_loss: 1.8458 - val_acc: 0.3915\n",
            "Epoch 985/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3499 - val_loss: 1.8488 - val_acc: 0.3908\n",
            "Epoch 986/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8953 - acc: 0.3501 - val_loss: 1.8463 - val_acc: 0.3910\n",
            "Epoch 987/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3497 - val_loss: 1.8454 - val_acc: 0.3915\n",
            "Epoch 988/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8947 - acc: 0.3509 - val_loss: 1.8480 - val_acc: 0.3909\n",
            "Epoch 989/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8950 - acc: 0.3508 - val_loss: 1.8474 - val_acc: 0.3906\n",
            "Epoch 990/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8940 - acc: 0.3494 - val_loss: 1.8472 - val_acc: 0.3903\n",
            "Epoch 991/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8944 - acc: 0.3491 - val_loss: 1.8488 - val_acc: 0.3903\n",
            "Epoch 992/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8960 - acc: 0.3480 - val_loss: 1.8467 - val_acc: 0.3922\n",
            "Epoch 993/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8959 - acc: 0.3498 - val_loss: 1.8449 - val_acc: 0.3911\n",
            "Epoch 994/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3503 - val_loss: 1.8463 - val_acc: 0.3906\n",
            "Epoch 995/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3506 - val_loss: 1.8488 - val_acc: 0.3909\n",
            "Epoch 996/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8952 - acc: 0.3500 - val_loss: 1.8459 - val_acc: 0.3907\n",
            "Epoch 997/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8949 - acc: 0.3489 - val_loss: 1.8437 - val_acc: 0.3925\n",
            "Epoch 998/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8962 - acc: 0.3491 - val_loss: 1.8462 - val_acc: 0.3905\n",
            "Epoch 999/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8969 - acc: 0.3503 - val_loss: 1.8483 - val_acc: 0.3891\n",
            "Epoch 1000/1000\n",
            "131559/131559 [==============================] - 0s 2us/sample - loss: 1.8964 - acc: 0.3494 - val_loss: 1.8460 - val_acc: 0.3901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owlUFzoqh2Ws",
        "colab_type": "code",
        "outputId": "9565fbb1-fc66-44e7-eb18-eb77073f50b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# take a dataframe row, make it an observation\n",
        "obs = scaler.transform(genreframe.iloc[62069:62070,7:20])\n",
        "obs"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.31026564, -0.14556117, -0.02462062, -0.85104841, -0.41424087,\n",
              "         0.49260707, -0.60230363, -0.07112041, -1.39063474, -0.65527578,\n",
              "         1.65594226,  0.21919423,  1.25783676]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r60EFM1IhbcF",
        "colab_type": "code",
        "outputId": "79bec8d7-56f0-4a24-d551-8583b1e0e0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# predict from the observation, look at the output\n",
        "pred = model.predict(obs)\n",
        "pred"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1134963 , 0.18399121, 0.03622173, 0.28088233, 0.0631346 ,\n",
              "        0.09686016, 0.08357186, 0.02284853, 0.03707801, 0.05090391,\n",
              "        0.00469987, 0.02631152]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOVe_tpkhbmn",
        "colab_type": "code",
        "outputId": "d8305f1c-b2a6-45f0-d811-6085c4d22f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# look at the actual content of the row\n",
        "genreframe.iloc[62069:62070,:].to_numpy()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Sharon Van Etten', 'Taking Chances', '1zqFc9MSJQhFmhCe7xyT5D',\n",
              "        39, 2014, 'folk', 102563, 0.153, 0.526, 230453, 0.462, 0.0139, 7,\n",
              "        0.1, -7.722, 0, 0.0262, 171.90599999999998, 4, 0.75, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koUZhK4xUjCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_list = ['alternative', 'country', 'dance', 'folk', 'grunge', 'indie', 'jazz', 'metal', 'pop', 'punk', 'rap', 'rock']\n",
        "\n",
        "def best_3(genre_vector):\n",
        "    \"\"\"takes a genre vector and returns the 3 most-fit genres as strings.\"\"\"\n",
        "    vector_list = genre_vector.tolist()[0]\n",
        "\n",
        "    best3_tuples =  sorted(zip(vector_list, genre_list), reverse=True)[:3]\n",
        "    best3_genres = [x[1] for x in best3_tuples]\n",
        "\n",
        "    return best3_genres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYNjDaWvVPMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "41e576da-0752-4c18-e8d1-cbcd3ca20b26"
      },
      "source": [
        "# best 3 genres\n",
        "best_3(pred)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['folk', 'country', 'alternative']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgmhWNfRhbYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "model.save('genre_NN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulPW4OLC1kVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}